# 日常实习-Redis面试题

小林coding:面试题 11111

[3 万字 + 40 张图 ｜ Redis 常见面试题（2023 版本） (qq.com)](https://mp.weixin.qq.com/s?__biz=MzUxODAzNDg4NQ==&mid=2247527565&idx=2&sn=f052a879d5c6c6c6cb69f4de668e71bd&chksm=f98d2827cefaa13182a5d8075187674e805368fab508bea2b7d5429aec1af2092df3e59571db&scene=178&cur_album_id=1790401816640225283#rd)

1. [(1条消息) 10题经典Redis面试题_努力学习的小白灬的博客-CSDN博客](https://blog.csdn.net/m0_52256357/article/details/125709819?ops_request_misc=%7B%22request%5Fid%22%3A%22168812811116800185863616%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=168812811116800185863616&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-14-125709819-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=redis面试题&spm=1018.2226.3001.4187)
2. [(1条消息) 面试还搞不懂redis，快看看这40道面试题（含答案和思维导图）_程序员追风的博客-CSDN博客](https://blog.csdn.net/Design407/article/details/103242874?ops_request_misc=%7B%22request%5Fid%22%3A%22168812811116800185863616%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=168812811116800185863616&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-10-103242874-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=redis面试题&spm=1018.2226.3001.4187)
3. [(1条消息) 「面试必背」Redis面试题（2022最新版）_redis面试必会6题经典_90后小伙追梦之路的博客-CSDN博客](https://blog.csdn.net/m0_67322837/article/details/125372575?ops_request_misc=%7B%22request%5Fid%22%3A%22168812811116800185863616%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=168812811116800185863616&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-9-125372575-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=redis面试题&spm=1018.2226.3001.4187)
4. [(1条消息) 全网最硬核 Redis 高频面试题解析（2021年最新版）_程序员囧辉的博客-CSDN博客](https://blog.csdn.net/v123411739/article/details/116109674?ops_request_misc=%7B%22request%5Fid%22%3A%22168812811116800185863616%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=168812811116800185863616&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-8-116109674-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=redis面试题&spm=1018.2226.3001.4187)
5. [(1条消息) JAVA经典面试题附答案(持续更新版)_java面试题_是华仔呀的博客-CSDN博客](https://blog.csdn.net/weixin_43495390/article/details/86533482?ops_request_misc=%7B%22request%5Fid%22%3A%22168812811116800185863616%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=168812811116800185863616&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-7-86533482-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=redis面试题&spm=1018.2226.3001.4187)
6. [(1条消息) 2023年Redis面试题（持续更新）_redis面试题2023_Geek-Banana的博客-CSDN博客](https://blog.csdn.net/qq1515312832/article/details/113880849?ops_request_misc=%7B%22request%5Fid%22%3A%22168812811116800185863616%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=168812811116800185863616&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-6-113880849-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=redis面试题&spm=1018.2226.3001.4187)
7. [(1条消息) 几率大的Redis面试题（含答案）__睶_的博客-CSDN博客](https://blog.csdn.net/Butterfly_resting/article/details/89668661?ops_request_misc=%7B%22request%5Fid%22%3A%22168812811116800185863616%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=168812811116800185863616&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-5-89668661-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=redis面试题&spm=1018.2226.3001.4187)
8. [(1条消息) redis面试题总结（附答案）_哪 吒的博客-CSDN博客](https://blog.csdn.net/guorui_java/article/details/117194603?ops_request_misc=%7B%22request%5Fid%22%3A%22168812811116800185863616%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=168812811116800185863616&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-4-117194603-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=redis面试题&spm=1018.2226.3001.4187)
9. [(1条消息) Redis面试题总结（2022最新版）_程序猿周周的博客-CSDN博客](https://blog.csdn.net/adminpd/article/details/122934938?ops_request_misc=%7B%22request%5Fid%22%3A%22168812811116800185863616%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=168812811116800185863616&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-3-122934938-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=redis面试题&spm=1018.2226.3001.4187)
10. [(1条消息) Redis面试题（2020最新版）_ThinkWon的博客-CSDN博客](https://blog.csdn.net/ThinkWon/article/details/103522351?ops_request_misc=%7B%22request%5Fid%22%3A%22168812811116800185863616%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=168812811116800185863616&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-2-103522351-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=redis面试题&spm=1018.2226.3001.4187)
11. [(1条消息) 20道经典Redis面试题_CSDN砖家的博客-CSDN博客](https://blog.csdn.net/weixin_40205234/article/details/124614720?ops_request_misc=%7B%22request%5Fid%22%3A%22168812811116800185863616%22%2C%22scm%22%3A%2220140713.130102334.pc%5Fall.%22%7D&request_id=168812811116800185863616&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~first_rank_ecpm_v1~hot_rank-1-124614720-null-null.142^v88^control_2,239^v2^insert_chatgpt&utm_term=redis面试题&spm=1018.2226.3001.4187)
12. 

# 搜集滴滴

6.Redis的持久化机制了解不了解？

​	AOF、AOF重写、RDB、混合。最搞笑的是，我把 binlog的3种格式（statement、row、mixed）记成了AOF的3种格式，一面二面我都这样说了，估计面试官也没想起来，也没说我有错。

7.问我主要用过 Redis 哪种数据结构，知不知道其底层原理？我回答了String的SDS原理，还回答了用了 MAP 做抢票的 Redis 内存标记。

4.怎样保证Redis预减库存不会出错呢？我一开始以为是MySQL、Redis数据同步的问题，还讲了一下RabbitMQ的持久化，后来才反应过来问的是Redis持久化机制。

5.你简历上说到了解关系型数据库MySQL和非关系型数据库Redis，那你为什么选用Redis和MySQL来做这个项目？随便说了下，不太懂。。。就MySQL好建表来当库存嘛，用Redis的话，它是高效缓存，能不能处理高并发情况。

6.**为什么Redis这么高效？**虽然单线程，但主要操作在内存中完成，瓶颈不是CPU等等八股，还回答到 I/O 多路复用机制，能处理多个 Socket 请求。
后面的问题都拓展了项目的情景，我只能记起来个大概。
7.如果我现在有这么一个场景，有一个演唱会抢票，我有3个演唱会抢票场次，每场100张票，该怎样实现？凭感觉回答分批次将100张票来初始化到Redis。
8.你的意思是，串行化实现对吧，那如果我3个抢票场次是同一时间进行的呢？回答了用Redis的Pipeline来进行批处理并行执行。
9.那你在一个Redis中执行，怎样确定是哪个场次的呢，你是不同场次同时抢票的呀？想了一会儿，用票的ID来进行判断，1~100就第一场这样。面试官说，可以在KEY上加上场次的ID，后来感觉确实比票ID更简单。
好像就这么些项目问题了。。。

\19. **Redis怎么实现短信验证登陆**
**\20. Redis缓存击穿、缓存雪崩、缓存穿透**

redis为什么这么快 单线程为什么这么快

简述项目，有几张表，项目中redis用来干嘛
场景题 数据库 redis一致性 先更新数据库再删缓存  先删除缓存再更新数据库（这要用到延时双删来保证一致性） 延时双删怎样实现的 加锁 只准一个线程操作



redis为什么这么快 单线程为什么这么快

1. Redis 用在哪里了，用了什么数据结构，为什么；不同数据结构的应用场景
2. Redis 缓存穿透怎么回事，怎么解决
3. 项目的难点，重点（讲了 Redis 数据一致性、缓存穿透）
4. Redis 分布式怎么做，知道哨兵吗

![image-20230719230224458](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202307192302518.png)

redis数据结构，如何实现

2.为什么要将热点数据放在Redis中

3.Redis的同步策略有什么（说错了，说成缓存更新策略了）

4.缓存穿透的产生原因和解决策略（布隆过滤器忘说了）



7.如果你自己设计一个类似Redis的缓存系统，你会考虑哪些问题（先整体设计，再设计细节）

8.Redis常用的数据类型以及他们的应用

9.Redis中的zset，如何实现一个排行榜的功能。



4.项目中用到了redis，介绍一下redis的架构
5.redis的线程模型



Redis在项目中的作用
缓存用啥结构
Redis存String转map和直接存map的区别
Redis持久化方式

3.redis 用的什么模式
4.哨兵模式和集群模式的区别5.哪一个支持的并发度更高6.

1.redis的持久化，AOF重写，数据结构，使用方式

\19. Redis为什么快？
\20. Redis的缓存穿透、缓存击穿以及缓存雪崩
\21. 布隆过滤器有哪一些缺点？

# 搜集的哈啰面试

1.mysql和redis怎么用的分布式锁
2.两个线程同时修改同一条数据时怎么增加并发

\11. Redis除了缓存之外，还有什么使用场景
\12. Redis生成唯一主键的思路，是生成后存放在Redis中等待使用还是请求时临时生成
\13. Redis的跳表

3、Redis 缓存过期触发回调函数处理订单超时关闭？有没有其他办法。

16、Redis事务过程原理？(开启事务，版本号机制实现)
17、Redis五大数据类型的使用场景。
18、Redis 缓存穿透、缓存雪崩、缓存击穿。如何解决
19、Redis的持久化机制。有什么优缺点。
20、Redis如何找出大量以某一个前缀开头的key。(有什么命令，不会)

12.redis缓存击穿 雪崩 穿透

13.持久化技术

14.分片集群

15.哨兵机制

16.淘汰策略

1. 秒杀怎么保证数据一致的，解决超卖
2. redis主要做了什么
3. 缓存穿透
4. 异步秒杀
5. 分布式锁实现原理
6. 分布式锁结构
7. 8、Redis过期删除策略 持久化方式

**Redis数据结构，sds（这里是面试官看我博客有写）**

3、`Redis`存储登录凭证具体怎么做的？

4、存储数据的`Redis`挂掉了怎么办？

5、`Redis`怎么持久化的？

6、`Redis`集群说一下

7、用`HyperLogLog`、`Bitmap`，当时怎么思考的？

8、它们是怎么实现的？

2、介绍项目里的redis实现点赞怎么实现的；redis 宕机了，数据没有存进去怎么办？集群了解过吗？redis过期淘汰策略

---

介绍项目里的redis实现点赞怎么实现的；redis 宕机了，数据没有存进去怎么办？集群了解过吗？redis过期淘汰策略

3、`Redis`存储登录凭证具体怎么做的？

4、存储数据的`Redis`挂掉了怎么办？

5、`Redis`怎么持久化的？

6、`Redis`集群说一下

7、用`HyperLogLog`、`Bitmap`，当时怎么思考的？

8、Redis过期删除策略 持久化方式

---

缓存数据库不一致怎么解决

MySQL和redis怎么保证数据一致性

---

1. 秒杀怎么保证数据一致的，解决超卖
2. redis主要做了什么
3. 缓存穿透
4. 异步秒杀
5. \- redis数据结构有哪几种，它们分别对应的应用场景

---

了解Redis缓存吗，项目中key有没有失效时间，怎么设计的

---

12.redis缓存击穿 雪崩 穿透--

13.持久化技术--

14.分片集群

15.哨兵机制

16.淘汰策略--

---

16、Redis事务过程原理？(开启事务，版本号机制实现)
17、Redis五大数据类型的使用场景。
18、Redis 缓存穿透、缓存雪崩、缓存击穿。如何解决
19、Redis的持久化机制。有什么优缺点。
20、Redis如何找出大量以某一个前缀开头的key。(有什么命令，不会)

3、Redis 缓存过期触发回调函数处理订单超时关闭？有没有其他办法。

---

redis底层数据结构

14.分片集群

15.哨兵机制

16.淘汰策略

 redis怎么做主从、集群、

# 黑马点评项目



**探店笔记**

图片上传是uploadecontroller  已经实现

缓存

查看笔记 包含用户信息 实体类加了字段 且标注表里面没有

**点赞+排行榜实现**

解决 1无限点赞 2排序   zset集合

stringRedisTemplate.opsForZSet

score使用时间戳，越早点赞排名越前 类似微信朋友圈

 zset集合 存储 点赞 保证点赞用户唯一 且有排序功能 **分数从小到大**

查询是否存在（指定成员分数

~~~
redis 127.0.0.1:6379> ZSCORE key member
返回分数值
~~~

点赞  数据库 liked  字段+1

添加zadd

命令

~~~
zrange student 0 -1 //查询所有元素
zrange zset 0 i  //0到i之前的元素
zrange zset 0 i  withscores//0到i之前的元素 带评分
zrangebyscore student 20 70 //查询score 20-70之间
zrevrangebyscore student 20 70 //数据从大到校排序
//添加
zadd student 60 Tom 72 Jerry 49 Jack 81 Bill
//删除
zrem student Tom
//增加
zincrby student 20 Tom
~~~

**好友关注**

表 tb_follow  主要存储用户id和关联的用户id

每一行数据是一个 a关注b记录

set集合操作

~~~
SADD key member1 [member2]
向集合添加一个或多个成员
SCARD key
获取集合的成员数
SREM key member1
	SINTER key1 [key2]
返回给定所有集合的交集   （共同关注
~~~

**秒杀**

1订单表要用全局唯一id  



2新增优惠券 

tb_voucher：普通券
tb_seckill_voucher：特价优惠券才需要填写；优惠券的库存、开始抢购时间，结束抢购时间

特价券有时间数量限制

3秒杀下单 接口

vouchordercontroller

- 判断开始结束时间和库存
- 判断库存再扣减库存 然后创建订单 订单id用全局id 代码1
- 问题
  - **超卖** 库存1时同时两个线程减库存 加锁 悲观vs乐观
  - 乐观锁解决超卖 操作时version+1 
  - 实际解决  库存>0就可以减去（库存=查询时候库存 失败概率太大）代码2
  - **一人一单问题** 避免重复下单
  - 判断库存后 订单前加一人一单判断逻辑 订单表 查询（优惠券id，用户id）
  - **一人一单并发问题** 都判断没有重复订单 同时插入数据库
  - 解决；乐观锁适合更新 直接比对原数据  悲观锁适合插入 代码3 syn和@Trasactional注解 锁住三部分
  - **集群下多个JVM 上述一人一单的syn锁失效**，用分布式锁 代码4
  - **分布式锁 获取锁后宕机 锁永远不释放**->t添加超时释放
  - **误删问题** ：超时释放后以为自己还有锁 释放了别人的锁->判断锁的标识是否一致再释放（前面value是线程id，JVM线程标识可能重复，改为uuid+线程id
  - **误删问题  极端情况**：释放自己锁的时候，判断锁标识和释放锁原子性不一致  判断完后 阻塞 超时释放  然后主动释放了别的线程的锁->lua脚本  execute执行lua脚本

**秒杀优化-消息队列**

前面下单逻辑，大量操作mysql 性能不好

把下单判断和操作库分开  redis存库存

![image-20230727101844334](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202307271018403.png)

判断能否下单的逻辑放入redis 后台慢慢执行数据库的

redis判断：看库存和是否下过单，然后userid和优惠券存入redis，过程要用lua操作

![image-20230727102354400](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202307271023474.png)

版本1 阻塞队列

版本2 消息队列

**共同关注**

set集合 SINTER s1 s2实现

要把关注列表放入redis  因此关注的时候要保存进redis

**feed流**

timline 推模式  因为用户不多，发送笔记就往所有粉丝的收件箱发（关注前发送的不会在推模式里面

保存blog 时 获取用户所有粉丝（数据库），往粉丝redis 里zset直接放blogid作为member  时间戳score

zset 实现 分页查询

滚动分页查询（因为列表会变化，不是正常分页查询

zrange key min max  查询范围内  

倒叙查询 最晚发的在最上面

四个参数

![image-20230710125444257](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202307262307506.png)

## redis在项目中的作用（redis主要做了什么

1用redis替代session 存储

2分布式锁

3消息队列

4用作mysql缓存

5zset点赞排行榜

6set集合求交集 共同关注

## 缓存用啥结构

String  Hash

## Redis存String转map和直接存map的区别



## 秒杀怎么保证数据一致的，解决超卖



## 异步秒杀



# 一、Redis基础

## --什么是redis

是基于内存的数据库，存储**键值对**，读写速度快，常用于缓存、分布式锁、消息队列；

- 内置多种数据类型 string set zset hash list 五大数据结构
- 支持事务和持久化机制
- 读写性能好

缺点：数据库容量受到物理内存的限制

## --为什么用作mysql缓存

1访问mysql数据从硬盘读取，redis是内存数据库 作为msyql缓存后，从内存读取数据 性能好 （修改数据时会出现双写一致性问题

2 直接访问redis能够承受请求远远大于mysql

## 为什么redis这么高效（这么快

- 内存存储：

- 单线程实现（redis6.0以前 ）：Redis使用单个线程处理请求，避免了多个线程之间线程切换和锁资源争用的开销。   注意：单线程是指的是在核心网络模型中，网络请求模块使用一个线程来处理，即一个线程处理所有网络请求。

- 虽然单线程，但主要操作在内存中完成，瓶颈不是CPU

  I/O多路复用机制  一个线程处理多个IO刘，监听这些端口的连接请求

## redis使用场景

缓存 分布式锁  消息队列

## Redis除了缓存之外，还有什么使用场景

分布式锁 消息队列

## Redis生成唯一主键的思路，是生成后存放在Redis中等待使用还是请求时临时生成



## Redis 缓存过期触发回调函数处理订单超时关闭？



## redis用在哪 用了什么数据结构

zset  点赞排行榜

set  好友关注

stream 秒杀异步

## 怎样保证Redis预减库存不会出错呢？

我一开始以为是MySQL、Redis数据同步的问题，还讲了一下RabbitMQ的持久化，后来才反应过来问的是Redis持久化机制。

## 你简历上说到了解关系型数据库MySQL和非关系型数据库Redis，那你为什么选用Redis和MySQL来做这个项目？

随便说了下，不太懂。。。就MySQL好建表来当库存嘛，用Redis的话，它是高效缓存，能不能处理高并发情况。



## 如果我现在有这么一个场景，有一个演唱会抢票，我有3个演唱会抢票场次，每场100张票，该怎样实现？

凭感觉回答分批次将100张票来初始化到Redis。

8.你的意思是，串行化实现对吧，那如果我3个抢票场次是同一时间进行的呢？回答了用Redis的Pipeline来进行批处理并行执行。
9.那你在一个Redis中执行，怎样确定是哪个场次的呢，你是不同场次同时抢票的呀？想了一会儿，用票的ID来进行判断，1~100就第一场这样。面试官说，可以在KEY上加上场次的ID，后来感觉确实比票ID更简单。
好像就这么些项目问题了。。。

## redis怎么实现短信验证登录

校验手机号格式是否正确 发送验证码  保存验证码到redis  用户手机号作为key

然后填写验证码后  比对redis存储的验证码   然后判断用户是否存在 不存在要创建用户 设置token 作为登录凭证  uuid生成





## redis为什么这么快 单线程为什么这么快



## 如果你自己设计一个类似Redis的缓存系统，你会考虑哪些问题（先整体设计，再设计细节）

## 项目中用到了redis，介绍一下redis的架构

# 二、数据类型

## Redis常见数据类型及其使用场景

### String（字符串）

#### 介绍

- 最常用的数据结构
- 二进制安全，可以存储任何类型：字符串、浮点数、图片、序列化后的对象、整数
- Redis C语言写的，但是没有用C的字符串，底层SDS 简单动态字符串。两者对比见 **底层数据结构（3点）**

#### 常用命令



| 命令                           | 介绍                             |
| ------------------------------ | -------------------------------- |
| SET key value                  | 设置指定 key 的值                |
| SETNX key value                | 只有在 key 不存在时设置 key 的值 |
| GET key                        | 获取指定 key 的值                |
| MSET key1 value1 key2 value2 … | 设置一个或多个指定 key 的值      |
| MGET key1 key2 ...             | 获取一个或多个指定 key 的值      |
| STRLEN key                     | 返回 key 所储存的字符串值的长度  |
| INCR key                       | 将 key 中储存的数字值增一        |
| DECR key                       | 将 key 中储存的数字值减一        |
| EXISTS key                     | 判断指定 key 是否存在            |
| DEL key（通用）                | 删除指定的 key                   |
| EXPIRE key seconds（通用）     | 给指定 key 设置过期时间          |

更多 Redis String 命令以及详细使用指南，请查看 Redis 官网对应的介绍：[https://redis.io/commands/?group=stringopen in new window](https://redis.io/commands/?group=string) 

**基本操作**：

```bash
> SET key value
OK
> GET key
"value"
> EXISTS key
(integer) 1
> STRLEN key
(integer) 5
> DEL key
(integer) 1
> GET key
(nil)
```

**批量设置**：

```bash
> MSET key1 value1 key2 value2
OK
> MGET key1 key2 # 批量获取多个 key 对应的 value
1) "value1"
2) "value2"
```

**计数器（字符串的内容为整数的时候可以使用）：**

```bash
> SET number 1
OK
> INCR number # 将 key 中储存的数字值增一
(integer) 2
> GET number
"2"
> DECR number # 将 key 中储存的数字值减一
(integer) 1
> GET number
"1"
```

**设置过期时间（默认为永不过期）**：

```bash
> EXPIRE key 60
(integer) 1
> SETEX key 60 value # 设置值并设置过期时间
OK
> TTL key
(integer) 56
```

#### 应用场景

**需要存储常规数据的场景**

- 举例：缓存 session、token、图片地址、序列化后的对象(相比较于 Hash 存储更节省内存)。
- 相关命令：`SET`、`GET`。

**需要计数的场景**

- 举例：用户单位时间的请求数（简单限流可以用到）、页面单位时间的访问数。
- 相关命令：`SET`、`GET`、 `INCR`、`DECR` 。

**分布式锁**

利用 `SETNX key value` 命令可以实现一个最简易的分布式锁（存在一些缺陷，通常不建议这样实现分布式锁）。

### List（列表）

#### 介绍

Redis 中的 List 其实就是链表数据结构的实现。我在 [线性数据结构 :数组、链表、栈、队列open in new window](https://javaguide.cn/cs-basics/data-structure/linear-data-structure.html) 这篇文章中详细介绍了链表这种数据结构，我这里就不多做介绍了。

许多高级编程语言都内置了链表的实现比如 Java 中的 `LinkedList`，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 List 的实现为一个 **双向链表**，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。

#### 常用命令

| 命令                        | 介绍                                       |
| --------------------------- | ------------------------------------------ |
| RPUSH key value1 value2 ... | 在指定列表的尾部（右边）添加一个或多个元素 |
| LPUSH key value1 value2 ... | 在指定列表的头部（左边）添加一个或多个元素 |
| LSET key index value        | 将指定列表索引 index 位置的值设置为 value  |
| LPOP key                    | 移除并获取指定列表的第一个元素(最左边)     |
| RPOP key                    | 移除并获取指定列表的最后一个元素(最右边)   |
| LLEN key                    | 获取列表元素数量                           |
| LRANGE key start end        | 获取列表 start 和 end 之间 的元素          |

更多 Redis List 命令以及详细使用指南，请查看 Redis 官网对应的介绍：[https://redis.io/commands/?group=listopen in new window](https://redis.io/commands/?group=list) 。

**通过 `RPUSH/LPOP` 或者 `LPUSH/RPOP`实现队列**：



```bash
> RPUSH myList value1
(integer) 1
> RPUSH myList value2 value3
(integer) 3
> LPOP myList
"value1"
> LRANGE myList 0 1
1) "value2"
2) "value3"
> LRANGE myList 0 -1
1) "value2"
2) "value3"
```

**通过 `RPUSH/RPOP`或者`LPUSH/LPOP` 实现栈**：



```bash
> RPUSH myList2 value1 value2 value3
(integer) 3
> RPOP myList2 # 将 list的最右边的元素取出
"value3"
```

我专门画了一个图方便大家理解 `RPUSH` , `LPOP` , `lpush` , `RPOP` 命令：

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202309062317628.png)

**通过 `LRANGE` 查看对应下标范围的列表元素**：



```bash
> RPUSH myList value1 value2 value3
(integer) 3
> LRANGE myList 0 1
1) "value1"
2) "value2"
> LRANGE myList 0 -1
1) "value1"
2) "value2"
3) "value3"
```

通过 `LRANGE` 命令，你可以基于 List 实现分页查询，性能非常高！

**通过 `LLEN` 查看链表长度**：

```bash
> LLEN myList
(integer) 3
```



### Hash（哈希）

#### 介绍

- String类型 键值对的映射表，适合存储对象，后续可修改对象某个字段的值
- 类似1.8前 HashMap，数组+链表

#### 常用命令

| 命令                                      | 介绍                                                     |
| ----------------------------------------- | -------------------------------------------------------- |
| HSET key field value                      | 设置指定哈希表中指定字段的值                             |
| HSETNX key field value                    | 只有指定字段不存在时设置指定字段的值                     |
| HMSET key field1 value1 field2 value2 ... | 同时将一个或多个 field-value (域-值)对设置到指定哈希表中 |
| HGET key field                            | 获取指定哈希表中指定字段的值                             |
| HMGET key field1 field2 ...               | 获取指定哈希表中一个或者多个指定字段的值                 |
| HGETALL key                               | 获取指定哈希表中所有的键值对                             |
| HEXISTS key field                         | 查看指定哈希表中指定的字段是否存在                       |
| HDEL key field1 field2 ...                | 删除一个或多个哈希表字段                                 |
| HLEN key                                  | 获取指定哈希表中字段的数量                               |
| HINCRBY key field increment               | 对指定哈希中的指定字段做运算操作（正数为加，负数为减）   |

更多 Redis Hash 命令以及详细使用指南，请查看 Redis 官网对应的介绍：[https://redis.io/commands/?group=hashopen in new window](https://redis.io/commands/?group=hash) 。



**模拟对象数据存储**：

```bash
> HMSET userInfoKey name "guide" description "dev" age 24
OK
> HEXISTS userInfoKey name # 查看 key 对应的 value中指定的字段是否存在。
(integer) 1
> HGET userInfoKey name # 获取存储在哈希表中指定字段的值。
"guide"
> HGET userInfoKey age
"24"
> HGETALL userInfoKey # 获取在哈希表中指定 key 的所有字段和值
1) "name"
2) "guide"
3) "description"
4) "dev"
5) "age"
6) "24"
> HSET userInfoKey name "GuideGeGe"
> HGET userInfoKey name
"GuideGeGe"
> HINCRBY userInfoKey age 2
(integer) 26
```



#### 应用场景

**对象数据存储场景**

- 举例：用户信息、商品信息、文章信息、购物车信息。
- 相关命令：`HSET` （设置单个字段的值）、`HMSET`（设置多个字段的值）、`HGET`（获取单个字段的值）、`HMGET`（获取多个字段的值

### Set（集合）

#### 介绍

- 无序集合，元素没有先后顺序但唯一，类似HashSet
- 区别List：判是否在集合，且不会重复元素
- 交集、差集、并集
- 可以实现，用户关注人和粉丝存在两个集合中

#### 常用命令

| 命令                                  | 介绍                                      |
| ------------------------------------- | ----------------------------------------- |
| SADD key member1 member2 ...          | 向指定集合添加一个或多个元素              |
| SMEMBERS key                          | 获取指定集合中的所有元素                  |
| SCARD key                             | 获取指定集合的元素数量                    |
| SISMEMBER key member                  | 判断指定元素是否在指定集合中              |
| SINTER key1 key2 ...                  | 获取给定所有集合的交集                    |
| SINTERSTORE destination key1 key2 ... | 将给定所有集合的交集存储在 destination 中 |
| SUNION key1 key2 ...                  | 获取给定所有集合的并集                    |
| SUNIONSTORE destination key1 key2 ... | 将给定所有集合的并集存储在 destination 中 |
| SDIFF key1 key2 ...                   | 获取给定所有集合的差集                    |
| SDIFFSTORE destination key1 key2 ...  | 将给定所有集合的差集存储在 destination 中 |
| SPOP key count                        | 随机移除并获取指定集合中一个或多个元素    |
| SRANDMEMBER key count                 | 随机获取指定集合中指定数量的元素          |

更多 Redis Set 命令以及详细使用指南，请查看 Redis 官网对应的介绍：[https://redis.io/commands/?group=setopen in new window](https://redis.io/commands/?group=set) 。

**基本操作**：

```bash
> SADD mySet value1 value2
(integer) 2
> SADD mySet value1 # 不允许有重复元素，因此添加失败
(integer) 0
> SMEMBERS mySet
1) "value1"
2) "value2"
> SCARD mySet
(integer) 2
> SISMEMBER mySet value1
(integer) 1
> SADD mySet2 value2 value3
(integer) 2
```

- `mySet` : `value1`、`value2` 。
- `mySet2`：`value2`、`value3` 。

**求交集**：

```bash
> SINTERSTORE mySet3 mySet mySet2
(integer) 1
> SMEMBERS mySet3
1) "value2"
```

**求并集**：

```bash
> SUNION mySet mySet2
1) "value3"
2) "value2"
3) "value1"
```

**求差集**：

```bash
> SDIFF mySet mySet2 # 差集是由所有属于 mySet 但不属于 A 的元素组成的集合
1) "value1"
```

#### 应用场景

**需要存放的数据不能重复的场景**

- 举例：网站 UV 统计（数据量巨大的场景还是 `HyperLogLog`更适合一些）、文章点赞、动态点赞等场景。
- 相关命令：`SCARD`（获取集合数量） 。

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202309062323550.png)

**需要获取多个数据源交集、并集和差集的场景**

- 举例：共同好友(交集)、共同粉丝(交集)、共同关注(交集)、好友推荐（差集）、音乐推荐（差集）、订阅号推荐（差集+交集） 等场景。
- 相关命令：`SINTER`（交集）、`SINTERSTORE` （交集）、`SUNION` （并集）、`SUNIONSTORE`（并集）、`SDIFF`（差集）、`SDIFFSTORE` （差集）。

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202309062323547.png)

**需要随机获取数据源中的元素的场景**

- 举例：抽奖系统、随机点名等场景。
- 相关命令：`SPOP`（随机获取集合中的元素并移除，适合不允许重复中奖的场景）、`SRANDMEMBER`（随机获取集合中的元素，适合允许重复中奖的场景）。

### Zset（有序集合）

#### 介绍

- 类似set 多score参数，类似HashMap+TreeSet
- 可以按score排序，按score范围获取元素









list set zset string hash

- String 类型的应用场景：缓存对象为JSON、常规计数、**分布式锁**、共享 session 信息等。
- List 类型的应用场景：消息队列（但是有两个问题：1. 生产者需要自行实现全局唯一 ID；2. 不能以消费组形式消费数据）等。
- Hash 类型：**缓存对象、购物车**等。
- Set 类型：聚合计算（并集、交集、差集）场景，比如**点赞**、**共同关注**、抽奖活动等。
- Zset 类型：**排序场景，比如排行榜**、电话和姓名排序等。

---

- BitMap（2.2 版新增）：二值状态统计的场景，比如签到、判断用户登陆状态、连续签到用户总数等；
- HyperLogLog（2.8 版新增）：海量数据基数统计的场景，比如百万级网页 UV 计数等；
- GEO（3.2 版新增）：存储地理位置信息的场景，比如滴滴叫车；
- Stream（5.0 版新增）：消息队列，相比于基于 List 类型实现的消息队列，有这两个特有的特性：自动生成全局唯一消息ID，支持以消费组形式消费数据。

## Redis 4种特殊数据结构 及 使用场景





## redis数据结构的底层原理

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202309051701384.png)

### SDS

### C语言字符串的缺陷

相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外，Redis 的 SDS API 是安全的，不会造成缓冲区溢出。



### SDS结构设计



### 链表





### 压缩列表





### 哈希表



### 整数集合



### 跳表





### quicklist



### listpack



### 

## 主要用过 Redis 哪种数据结构，知不知道其底层原理？

string底层  简单动态字符串SDS  

- 不仅保存文本数据，还可以保存二进制数据
- 获取字符串长度时间复杂度O(1)



List底层quicklist



Hash底层   **listpack**或哈希表

set 哈希表或者整数集合

zset listpack或者跳表



## Redis中的zset，如何实现一个排行榜的功能。

黑马点评实现 key value score

## `Redis`存储登录凭证具体怎么做的？

token，前端访问会带有token

## 用`HyperLogLog`、`Bitmap`，当时怎么思考的？

## `HyperLogLog`、`Bitmap`怎么实现



## 介绍项目里的redis实现点赞怎么实现的

## redis 宕机了，数据没有存进去怎么办？



## 了解Redis缓存吗，项目中key有没有失效时间，怎么设计的

用户登录凭证  30min

验证码2分钟



## 4、存储数据的`Redis`挂掉了怎么办？

# 三、持久化

## 简述redis持久化机制。有什么优缺点。

## 概念

redis读写操作在内存中，防止内存数据丢失

持久化是为了重用redis数据，或者防止系统故障，要把数据写入磁盘

redis默认持久化是RDB，重启加载之前的快照

## 持久化方式

持久化有三种方式

1.快照rdb

2.只追加文件AOF

3.混合持久化 redis4.0新增

### 1 RDB 快照

概念：指定的时间间隔内把**内存中的数据集快照**写入磁盘，恢复时是将快照文件直接读入内存；

特点

- 记录某一瞬间的内存数据，记录实际数据
- 回复效率更高，只需将RDB文件读入内存，无需执行写操作命令
- 使用：save bgsave命令生成快照文件  save会阻塞主线程  bgsasve不会阻塞主线程 生成子进程
- 也可配置redis.conf文件  后台生成

优点：

适合大规模数据恢复，对数据完整性和一致性要求不高

缺点：

间隔一段时间备份，宕机时会丢失最后一次快照后的修改



### 2 AOF文件

概念 ：以日志形式记录每个写操作，记录写命令，只许追加不可改写文件，redis启动之初会读取该文件重新构建数据（根据写指令从前往后执行恢复数据

>  用 AOF 日志的方式来恢复数据其实是很慢的，因为 Redis 执行命令由单线程负责的，而 AOF 日志恢复数据的方式是顺序执行日志里的每一条命令，如果 AOF 日志很大，这个「重放」的过程就会很慢了。

![AOF 工作基本流程](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202309062352193.png)

特点

- 默认不开启，修改redis.conf
- 只记录写操作命令，读操作无意义
- 先执行写操作命令后，才将该命令记录到 AOF 日志
  - 好处 
    - 1避免额外的检查开销 （先记录命令需要检查命令是否正确
    - 2不会阻塞当前写操作命令的执行
- 风险： 1写操作命令和记录日志两个过程，有丢失数据风险 2不会阻塞当前写命令，但有可能阻塞下一个命令，因为写入日志的操作也是主进程完成

三种写回策略

写命令会加载到缓冲区，再到内核缓冲区  何时写入磁盘 三种策略

- always：写操作后就写回（最大程度保证数据不丢失，影响主进程的性能；
- everysec：每隔一秒将内核缓冲区的内容写回硬盘（如果上一秒的写操作命令日志没有写回到硬盘，发生了宕机，这一秒内的数据自然也会丢失。
- no ：操作系统决定何时写回硬盘（操作系统写回硬盘的时机是不可预知的，如果 AOF 日志内容没有写回硬盘，一旦服务器宕机，就会丢失不定数量的数据。

![image-20230723232436974](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202307232324073.png)

三种策略区别是调用fsync函数的时机

流程

**命令追加（append）**：所有的写命令会追加到 AOF 缓冲区中。

**文件写入（write）**：将 AOF 缓冲区的数据写入到 AOF 文件中。这一步需要调用`write`函数（系统调用），`write`将数据写入到了系统内核缓冲区之后直接返回了（延迟写）。注意！！！此时并没有同步到磁盘。

**文件同步（fsync）**：AOF 缓冲区根据对应的持久化方式（ `fsync` 策略）向硬盘做同步操作。这一步需要调用 `fsync` 函数（系统调用）， `fsync` 针对单个文件操作，对其进行强制硬盘同步，`fsync` 将阻塞直到写入磁盘完成后返回，保证了数据持久化。

**文件重写（rewrite）**：随着 AOF 文件越来越大，需要定期对 AOF 文件进行重写，达到压缩的目的。

**重启加载（load）**：当 Redis 重启时，可以加载 AOF 文件进行数据恢复。



优点

aof数据安全性较好，每次写操作都生成

只追加写操作命令到aof文件， rdb是保存快照数据集，较为复杂

缺点

1 aof文件大于rdb文件  恢复速度慢

2 aof运行效率慢  每秒同步效率较好

### 3 RDB和AOF结合



## RDB AOF对比



## 如何选择某一种持久化方式

数据安全性要求高选择AOF

可以忍受文件丢失RDB

## --AOF重写机制

对AOF文件瘦身  对一个属性的多次修改只用保存最后一次的写命令





# 四、线程模型

## --redis是单线程吗

单线程指的是**「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的**

redis会启动后台线程  

1处理关闭文件

2 AOF刷盘

## --redis单线程还那么快（网络I/O和执行命令

- redis大部分操作都在内存中完成，redis瓶颈并非CPU
- 避免了**多线程之间的竞争**，省去了多线程切换带来的时间和性能上的开销，而且也不会导致死锁问题。
- I/O多路复用机制：处理大量的客户端Socket请求；
  - ，IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听 Socket 和已连接 Socket。内核会一直监听这些 Socket 上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。



## --redis6.0后为何引入多线程

6.0后引入多个I/O线程处理网络请求，随着网络硬件性能的提升，Redis的性能有时会出现在网络I/O的处理上

**但是对于命令的执行，Redis 仍然使用单线程来处理**

## Redis如何找出大量以某一个前缀开头的key。(有什么命令，不会)

# 五、Redis应用





# 六、Redis事务

## --概念

单个redis命令执行是原子性，redis事务不是原子性，理解为打包的批量执行的脚本，中间失败的指令不会引起回滚，也不影响后续指令执行

- 具有隔离性，不会被其他命令请求打断

## Redis事务过程原理？(开启事务，版本号机制实现)

四个命令  multi  exec  discard  watch

1. 开始事务（`MULTI`）；
2. 命令入队(批量操作 Redis 的命令，先进先出（FIFO）的顺序执行)；
3. 执行事务(`EXEC`)。

discard清空事务队列

watch监控  如果命令被修改  就执行失败

# 功能篇

## 过期删除策略



## 内存淘汰策略



# 七、Redis缓存

缓存过多需要删除/更新

涉及三个问题

内存淘汰 八个策略

超时剔除 三种策略

主动更新 四种方案

![1653322506393](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202307241700053.png)

## 过期删除策略

redis采用**惰性删除+定期删除**配合使用

常用三种：

- 定时删除
- 惰性删除
- 定期删除

**定时删除**

做法

**在设置 key 的过期时间时，同时创建一个定时事件，当时间到达时，由事件处理器自动执行 key 的删除操作。**

优点

对内存最友好，尽快删除

缺点

占用CPU时间，过期key多时，内存不紧张CPU紧张的时候效率受影响

**惰性删除**

**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。**

优点

对CPU时间最友好

缺点

过期key没有被访问，就一直留在数据库中，

**定期删除**

**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查，并删除其中的过期key。**

优点

- 通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。

缺点

- 内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。
- 难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好；如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。

redis如何实现惰性删除



redis如何实现定期删除



## 内存淘汰策略

> 过期删除策略，是删除已过期的 key；
>
> 内存淘汰：当 Redis 的运行内存已经超过 Redis 设置的最大内存之后，则会使用内存淘汰策略删除符合条件的 key，以此来保障 Redis 高效的运行。

八种

1. 不进行数据淘汰
   1. noeviction 默认的不淘汰任何数据
2. 进行数据淘汰
   1. 设置的过期时间的数据淘汰
      1. volatile-random
      2. volatile-ttl 优先淘汰更早过期的键值
      3. volatile-lru
      4. volatile-lfu
   2. 在所有数据范围内进行淘汰
      1. allkeys-random
      2. allkeys-lru 最久未使用
      3. allkeys-lfu 最少使用

## 缓存更新策略=缓存读写策略=同步策略

该策略解决的是 修改数据库的同时如何修改缓存

三种策略各有优劣

![image-20230724165110286](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202307241651359.png)

### Cache Aside Pattern(旁路缓存模式)

概述

由缓存的调用者，在更新数据库的同时更新缓存

- 较常用，适合读请求多场景
- 服务端需要同时维系 db 和 cache，并且是以 db 的结果为准。

#### **缓存读写步骤**

**写**：

- 先更新 db

- 然后直接删除 cache 。

  ![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202309062356252.png)

**读** :

- 从 cache 中读取数据，读取到就直接返回
- cache 中读取不到的话，就从 db 中读取数据返回
- 再把数据放到 cache 中。

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202309062356518.png)

#### 问题：先后顺序

“**在写数据的过程中，可以先删除 cache ，后更新 db 么？**”

**答案：** 不行，会造成 **数据库（db）和缓存（Cache）数据不一致**的问题。 具体看双写一致性问题。

> 请求 1 先把 cache 中的 A 数据删除 -> 请求 2 从 db 中读取数据->请求 1 再把 db 中的 A 数据更新

“**在写数据的过程中，先更新 db，后删除 cache 就没有问题了么？**”

**答案：** 理论上来说还是可能会出现数据不一致性的问题，不过概率非常小，因为缓存的写入速度是比数据库的写入速度快很多。

> 请求 1 从 db 读数据 A-> 请求 2 更新 db 中的数据 A（此时缓存中无数据 A ，故不用执行删除缓存操作 ） -> 请求 1 将数据 A 写入 cache；此时旧数据写入缓存，数据不一致

#### **缺点**

**缺陷 1：首次请求数据一定不在 cache 的问题**

解决办法：可以将热点数据可以提前放入 cache 中。

**缺陷 2：写操作比较频繁的话导致 cache 中的数据会被频繁被删除，这样会影响缓存命中率 。**

**解决办法：**

1数据库和缓存数据强一致场景：更新 db 的时候同样更新 cache，不过我们需要加一个锁/分布式锁来保证更新 cache 的时候不存在线程安全问题。

2可以短暂地允许数据库和缓存数据不一致的场景：更新 db 的时候同样更新 cache，但是给缓存加一个比较短的过期时间，这样的话就可以保证即使数据不一致的话影响也比较小。

### Read/Write Through Pattern(读写穿透)

概述

缓存与数据库整合为一个服务由服务来维护一致性。调用者调用该服务，无需关心缓存一致性问题。

- 服务端把 cache 视为主要数据存储，从中读取数据并将数据写入其中。
- cache 服务负责将此数据读取和写入 db，从而减轻了应用程序的职责。
- 非常少见。抛去性能方面的影响，大概率是因为我们经常使用的分布式缓存 Redis 并**没有提供 cache 将数据写入 db** 的功能。

#### 读写步骤

**写（Write Through）：**

- 先查 cache，cache 中不存在，直接更新 db。
- cache 中存在，则先更新 cache，然后 cache 服务自己更新 db（**同步更新 cache 和 db**）。

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202309070000927.png)

**读(Read Through)：**

- 从 cache 中读取数据，读取到就直接返回 。
- 读取不到的话，先从 db 加载，写入到 cache 后返回响应。

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202309070000957.png)

Read-Through Pattern 实际只是在 Cache-Aside Pattern 之上进行了封装。在 Cache-Aside Pattern 下，发生读请求的时候，如果 cache 中不存在对应的数据，是由客户端自己负责把数据写入 cache，而 Read Through Pattern 则是 cache 服务自己来写入缓存的，这对客户端是透明的。

和 Cache Aside Pattern 一样， Read-Through Pattern 也有首次请求数据一定不再 cache 的问题，对于热点数据可以提前放入缓存中

### Write Behind Pattern(异步缓存写入)

概述

调用者只操作缓存，由其它线程异步的将缓存数据持久化到数据
库，保证最终一致。

- 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 db 的读写。
- 但是**Read/Write Through 是同步更新 cache 和 db，而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。**（这种方式对数据一致性带来了更大的挑战，比如 cache 数据可能还没异步更新 db 的话，cache 服务可能就就挂掉了。）
- 非常少见，但是不代表它的应用场景少，比如消息队列中消息的异步写入磁盘、MySQL 的 Innodb Buffer Pool 机制都用到了这种策略。

Write Behind Pattern 下 db 的写性能非常高，非常适合一些数据经常变化又对数据一致性要求没那么高的场景，比如浏览量、点赞量。

## mysql和redis双写一致性（四种方案

> 相关面试题：
>
> ​	1.数据库和缓存如何保证一致性？

修改数据时，数据库数据会变化，要保证缓存和数据库数据同步

没有必要每次都更新缓存，因为更新操作实际上只有最后一次生效，我们可以把缓存删除，等待再次查询时，将缓存中的数据加载出来

四种方案

1.先更新数据库，再更新缓存

2.先更新缓存，再更新数据库：

3.先删除缓存，后更新数据库√

4.先更新数据库，后删除缓存

---





### 1先删除缓存再更新数据库

（这要用到延时双删来保证一致性） 延时双删怎样实现的 加锁 只准一个线程操作

该方案会出问题：

请求 1 先写数据 A，请求 2 随后读数据 A 的话，就很有可能产生数据不一致性的问题。

这个过程可以简单描述为：

> 请求 1 先把 cache 中的 A 数据删除 -> 请求 2 从 db 中读取数据->请求 1 再把 db 中的 A 数据更新

------

---

请求 A（更新操作） 和请求 B（查询操作）

1. 请求A进行写操作，删除缓存
2. 请求B查询发现缓存不存在
3. 请求B去数据库查询得到旧值
4. 请求B将旧值写入缓存
5. 请求A将新值写入数据库

导致不一致的情况出现；如果不给缓存设置过期时间策略 数据永远脏数据

解决方法

1.延时双删

2.更新与读取操作进行异步串行化

### 2先更新数据库再删缓存  

问题：

情况1

如果更新数据库成功，删除缓存失败，此时读取缓存是错误的数据

情况2

请求 1 先读数据 A，请求 2 随后写数据 A，并且数据 A 在请求 1 请求之前不在缓存中的话，也有可能产生数据不一致性的问题。

这个过程可以简单描述为：

> 请求 1 从 db 读数据 A-> 请求 2 更新 db 中的数据 A（此时缓存中无数据 A ，故不用执行删除缓存操作 ） -> 请求 1 将数据 A 写入 cache



## 缓存穿透 及解决方案

缓存穿透是指**缓存和数据库中都没有的数据**，而用户不断发起请求。

- 第一种方案，非法请求的限制；
- 第二种方案，缓存空值或者默认值；
- 第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；

## 布隆过滤器有什么缺点



## 缓存击穿 及解决方案

缓存击穿是指**缓存中没有但数据库中有的数据**（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。

主要指**热点数据**

- 互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。
- 不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；

## 缓存雪崩 及解决方案

缓存雪崩是指缓存中**数据大批量到过期时间or redis宕机，而查询数据量巨大，引起数据库压力过大甚至down机**。

- 大量数据同时过期
  - 均匀设置过期时间；
  - 互斥锁；
  - 双 key 策略；
  - 后台更新缓存；
- redis故障宕机
  - 服务熔断或请求限流机制；
  - 构建 Redis 缓存高可靠集群；

# 分布式锁

## 什么是分布式锁

锁就是同步工具，保证共享资源同一时刻只能被一个线程访问，但是java的锁只能保证单机的时候有效

分布式锁就是 满足分布式系统下多进程可见并且互斥的锁。

实现思路 整个系统提供一个全局唯一的获取锁的东西

满足特性

互斥

安全

高性能

多进程可见

常见

mysql、redis、zookeeper

mysql性能一般  

redis实现 string结构

setnx key test

 set if not exist

del key

## 分布式锁原理

setnx命令

## 分布式锁结构



## mysql和redis怎么用的分布式锁



# 消息队列

## 刚刚说可以实现消息队列 谈谈mq

mq的场景

- 解耦
- 异步
- 削峰

解耦

如果A除了插入数据库，还要增加日志文件 还要发邮件，就要在原有代码扩展，如果使用MQ就放入消息队列中 ，从MQ获取消息在处理  好处是提高灵活性，扩展性

异步

将一些非核心流程，日志、短信、邮件 通过MQ方式异步处理，缩短主流程响应时间，提高用户体验

削峰

MQ本质是业务的排队。好处是避免高并发压垮系统的关键组件

缺点

1.系统可用性降低：系统引入的外部依赖越多，越容易挂掉。

2.系统复杂度提高：一致性问题、如何保证消息不被重复消费、如何保
证消息可靠性传输等。

3.一致性问题：A处理成功直接返回  接受消息的BCD  有一个写库失败 就不一致

# 八、高可用篇（主从 哨兵 集群）

## Redis 主从复制（主从节点之间如何同步数据）

### 前言

单机 Redis 存在单点风险问题，也就是说，如果唯一的一个 Redis 节点宕机的话，就会导致大量的请求直接被打到数据库，严重的情况下，数据库很可能会直接被干宕机了。

这个时候，保障 Redis 服务的高可用就成为了我们不得不面对的问题。

如何保证 Redis 服务高可用？ 最简单的一种办法就是基于 主从复制 搭建一个 Redis 集群，master（主节点）主要负责处理写请求，slave（从节点）主要负责处理读请求。



如果 master 宕机的话，从 slave 中选出一台作为 master 即可实现故障转移（Failover）。



是不是有点类似于 MySQL 的读写分离？这其实就是一种典型的多副本/备份的思想，经常被用在高可用架构上。

### 什么是主从复制

简单来说，**主从复制** 就是将一台 Redis 主节点的数据复制到其他的 Redis 从节点中，尽最大可能保证 Redis 主节点和从节点的数据是一致的。主从复制是 Redis 高可用的基石，我们后面介绍到的 Redis Sentinel 以及 Redis Cluster 都依赖于主从复制。

主从复制这种方案不仅保障了 Redis 服务的高可用，还实现了读写分离，提高了系统的并发量，尤其是读并发量。

主从复制这种方案基于 [Redis replication](https://redis.io/docs/manual/replication/)（默认使用异步复制），开发者可以通过 replicaof （Redis 5.0 之前是 slaveof 命令）命令来配置各个 Redis 节点的主从关系。



配置完成之后，主从节点之间的数据同步会自动进行，不需要人为插手。



至于具体要配置多少 slave 节点，主要取决于项目的读吞吐量，因为 slave 节点分担的是读请求，写请求由 master 节点负责。





### 主从复制下从节点会主动删除过期数据吗？

类似的问题：

●主从复制下会读取到过期的数据吗？
●主从复制下如何避免读取到过期的数据?

这是一个常见的问题，面试中也经常会问到。

我们知道，Redis 中常用的过期数据的删除策略就两个（重要！自己造缓存轮子的时候需要格外考虑的东西）：

●惰性删除 ：只会在取出 key 的时候才对数据进行过期检查。这样对 CPU 最友好，但是可能会造成太多过期 key 没有被删除。
●定期删除 ： 每隔一段时间抽取一批 key 执行删除过期 key 操作。并且，Redis 底层会通过限制删除操作执行的时长和频率来减少删除操作对 CPU 时间的影响。

定期删除对内存更加友好，惰性删除对 CPU 更加友好。两者各有千秋，所以 Redis 采用的是 定期删除+惰性/懒汉式删除 。

那客户端读取从节点会读取到过期数据么？ 答案是：有可能，但要看具体的情况。

●Redis 3.2 版本之前，客户端读从库并不会判断数据是否过期，有可能返回过期数据。Redis 3.2 版本及之后，客户端读从库会先判断数据是否过期，如果过期的话，就会删除对应的数据并返回空值。
●采用 EXPIRE 或者PEXPIRE设置过期时间的话，表示的是从执行这个命令开始往后 TTL 时间过期。如果从节点同步执行命令因为网络等原因延迟的话，客户端就可能会读取到过期的数据（如下图所示，客户端在 T3-T4 之间读取到的就是过期数据）。这种情况可以考虑使用 EXPIREAT 和 PEXPIREAT，这两个命令语义和效果和 EXPIRE 或者PEXPIRE类似，但不是指定 TTL（生存时间）的秒数/毫秒数，而是使用绝对的 [Unix 时间戳](http://en.wikipedia.org/wiki/Unix_time)（自 1970 年 1 月 1 日以来的秒数）。由于设置的是时间点，主从节点的时钟需要保持一致。

### 主从节点之间如何同步数据？

> 类似的问题：
>
> ●主从复制的原理是什么？
> ●master 节点的数据是如何同步给 slave 节点的?
> ●复制积压缓冲区的有什么用?



这个问题其实还挺复杂的，Redis 主从复制经历了多次改进，每一次的改进都解决了上一个版本的一些痛点。想要彻底搞懂的话，我们需要耐心地看看 Redis 主从复制的演进历程，这里主要分为下面 3 个阶段：



●Redis 2.8 之前的 SYNC 方案

●Redis 2.8 PSYNC 方案

●Redis 4.0 PSYNC2.0 方案



为了让大家更好理解，我这里已经是经我所能使用大白话讲解了，并且，还配有图解。



需要注意：每一个版本的方案基本都是持续优化改进得到的。



#### Redis 2.8 之前的 SYNC 方案 

Redis 在 2.8 版本之前都是基于 [SYNC](https://redis.io/commands/sync/) 命令执行全量同步，整个步骤简化后是这样的：

> 1slave 向 master 发送 SYNC 命令请求启动复制流程；
>
> 2master 收到 SYNC 命令之后执行 [BGSAVE](https://redis.io/commands/bgsave/) 命令（子线程执行，不会阻塞主线程）生成 RDB 文件（dump.rdb）；
>
> 3master 将生成的 RDB 文件发送给 slave；
>
> 4slave 收到 RDB 文件之后就开始加载解析 RDB 同步更新本地数据；
>
> 5更新完成之后，slave 的状态相当于是 master 执行 BGSAVE 命令时的状态。master 会将 BGSAVE 命令之后接受的写命令缓存起来，因为这部分写命令 slave 还未同步；
>
> 6master 将自己缓存的这些写命令发送给 slave，slave 执行这些写命令同步 master 的最新状态；
>
> 7slave 到这个时候已经完成全量复制，后续会通过和 master 维护的长连接来进行命令传播，同步最新的写命令



master 为每一个 slave **单独** 开辟一块 **replication buffer（复制缓存区）**来记录 RDB 文件生成后 master 收到的所有写命令。



replication buffer 可以通过下面这些参数来控制，超过指定的阈值后，master 就会强制断开对应 slave 的连接。





执行 BGSAVE 命令之后，Redis 主线程会专门 fork 一个子进程，子进程共享主线程的内存数据。子进程会读取主线程中的内存数据写入 RDB 文件中，不会阻塞主线程。



> 这里说 Redis 主线程而不是主进程的主要是因为 Redis 启动之后主要是通过单线程的方式完成主要的工作。如果你想将其描述为 Redis 主进程，也没毛病。



虽然 BGSAVE 子进程写入 RDB 的工作不会阻塞主线程，但会对机器的 CPU 资源和内存资源产生影响，严重的情况下甚至会直接把 Redis 服务干宕机。



●写入 RDB 的过程中，为了避免影响写操作，主线程修改的内存数据会被复制一份副本，BGSAVE 子进程把这个副本数据写入 RDB 文件。如果修改内存数据的请求比较多的话，生成内存数据副本产生的内存消耗是非常大的。这个过程称为 Copy On Write（写时复制，COW） ，操作系统层面提供的机制。

●大量的写时复制会产生大量的分页错误（也叫缺页中断、页缺失），消耗大量的 CPU 资源。



也就是说，通过 BGSAVE 操作属于重量级操作，会对机器的 CPU 资源和内存资源产生影响。在生产环境中，我们应该尽量避免在 master 实例上频繁执行 BGSAVE 命令。



除了上面这个问题之外，Redis 在 2.8 版本之前主从复制还存在下面这些迫切需要解决的问题：



●slave 加载 RDB 的过程中不能对外提供读服务。

●slave 和 master 断开连接之后，slave 重新连上 master 需要重新进行全量同步。



#### Redis 2.8 PSYNC 方案 

Redis 2.8 版本 SYNC 命令被 [PSYNC](https://redis.io/commands/psync/) 取代，PSYNC 格式如下（相比较于 SYNC 命令，多了两个参数）：

~~~bash
PSYNC replicationid offset
~~~



PSYNC 解决了 slave 和 master 断开连接之后需要重新进行全量同步的问题。不过，部分情况（比如 slave 突然宕机或者被重启）重连之后依然需要进行全量同步。



具体是怎么解决的呢？原理其实也很简单，slave 会记录 master 的运行 id （也就是 runid）和自己的复制进度/偏移量（slave_repl_offset）。



每个 Redis 节点启动时都有一个 40 字节随机字符串作为运行 id，你可以通过 info server 命令查看 runid 的值。

master 也会记录自己写入缓冲区的偏移量（master_repl_offset），如果 runid 匹配的话，通过 slave_repl_offset 和 master_repl_offset 就可以确认 slave 缺少的数据是否在缓冲区中以及缺少的具体是哪一部分的数据。

这里集合 Redis 的源码简单介绍一下整个过程，源码地址：https://github.com/redis/redis/blob/2.8/src/replication.c。

masterTryPartialResynchronization() (replication.c中的一个方法)的部分重要源码：

#### Redis 4.0 PSYNC2.0 方案

PSYNC 方案中，我们通过 runid（master 的 id）+ offset（复制偏移量）来实现增量同步。不过，由于主从切换之后新选出来的 master 的 runid 和 offset 都会发生变化，依然需要进行全量同步。

Redis 4.0 PSYNC2.0 方案优化了 PSYNC 方案的增量同步方案，即使发生了主从切换，依然有可能进行增量同步而不是必须要全量同步。

举个例子：master 有 2 个 slave(slave1 和 slave2)，master 宕机后，slave1 成为了新的 master。PSYNC 方案中，slave2 只能和新的 master 进行全量同步（master 的 runid 已经改变了）。PSYNC2.0 方案中，slave2 是有可能是可以和新的 master 进行增量同步的。

为了达到这一效果，PSYNC2.0 舍弃了 runid 的概念了，取而代之的是replid 和 replid2：

●对于 master 来说，replid 就是自己的复制 id。没有发生主从切换之前，replid2为空。发生主从切换之后，新的 master 的 replid2是旧 master （前一个自己同步的 master） 的 replid，在主从角色切换的时候会用到。
●对于 slave 来说，replid 保存的是自己当前正在同步的 master 的 replid。replid2保存的是旧 master 的 replid，在主从角色切换的时候会用到。

还有两个和偏移量相关的字段：

●master_repl_offset : 当前的复制偏移量。
●second_replid_offset ：没有发生主从切换之前，second_replid_offset的值为 -1。发生主从切换之后，新的 master 的 second_replid_offset是旧 master 的复制偏移量。

### 为什么主从全量复制使用RDB而不是AOF

>  题其实本质是在对比 RDB 和 AOF 这两种持久化方式。

●**文件大小角度：**RDB 文件存储的内容是经过压缩的二进制数据，文件很小。AOF 文件存储的是每一次写命令，类似于 MySQL 的 binlog 日志，通常会必 RDB 文件大很多。因此，传输 RDB 文件更节省带宽，速度也更快。
●**恢复速度：**使用 RDB 文件恢复数据，直接解析还原数据即可，不需要一条一条地执行命令，速度非常快。而 AOF 则需要依次执行每个写命令，速度非常慢。也就是说，与 AOF 相比，恢复大数据集的时候，RDB 速度更快。
●**刷盘策略：**AOF 需要选择合适的刷盘策略，如果刷盘策略选择不当的话，会影响 Redis 的正常运行。并且，根据所使用的刷盘策略，AOF 的速度可能会慢于 RDB。

### 主从复制方案有什么痛点

主从复制方案下，master 发生宕机的话可以手动将某一台 slave 升级为 master，Redis 服务可用性提高。slave 可以分担读请求，读吞吐量大幅提高。

**缺点：**

但其缺陷也很明显，一旦 master 宕机，我们需要从 slave 中手动选择一个新的 master，同时需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。人工干预大大增加了问题的处理时间以及出错的可能性。

这个时候你肯定在想：如果能够自动化地完成故障切换就好了！我们后面介绍的 Redis Sentinel（哨兵）就可以帮助我们来解决这个痛点。

另外，主从复制方案在高并发场景下能力有限。如果缓存的数据量太大或者并发量要求太高，主从复制就没办法满足我们的要求了。

主从复制和 Redis Sentinel 这两种方案都不支持横向扩展来缓解写压力以及解决缓存数据量过大的问题。我们后面介绍的 Redis Cluster（官方切片集群解决方案）就可以帮助我们来解决这个痛点。

## Redis Sentinel 哨兵（如何实现自动化故障转移）

普通的主从复制方案下，一旦 master 宕机，我们需要从 slave 中手动选择一个新的 master，同时需要修改应用方的主节点地址，还需要命令所有从节点去复制新的主节点，整个过程需要人工干预。人工干预大大增加了问题的处理时间以及出错的可能性。

我们可以借助 Redis 官方的 Sentinel（哨兵）方案来帮助我们解决这个痛点，实现自动化地故障切换。

建议带着下面这些重要的问题（面试常问）阅读：

1什么是 Sentinel？ 有什么用？
2Sentinel 如何检测节点是否下线？主观下线与客观下线的区别?
3Sentinel 是如何实现故障转移的？
4为什么建议部署多个 sentinel 节点（哨兵集群）？
5Sentinel 如何选择出新的 master（选举机制）?
6如何从 Sentinel 集群中选择出 Leader ？
7Sentinel 可以防止脑裂吗？

### 什么是Sentinel?

Sentinel（哨兵） 只是 Redis 的一种运行模式 ，不提供读写服务，默认运行在 26379 端口上，依赖于 Redis 工作。Redis Sentinel 的稳定版本是在 Redis 2.8 之后发布的。

Redis 在 Sentinel 这种特殊的运行模式下，使用专门的命令表，也就是说普通模式运行下的 Redis 命令将无法使用。

通过下面的命令就可以让 Redis 以 Sentinel 的方式运行:

~~~bash
redis-sentinel /path/to/sentinel.conf
或者
redis-server /path/to/sentinel.conf --sentinel
~~~

Redis 源码中的sentinel.conf是用来配置 Sentinel 的，一个常见的最小配置如下所示：

~~~
// 指定要监视的 master
// 127.0.0.1 6379 为 master 地址
// 2 表示当有 2 个 sentinel 认为 master 失效时，master 才算真正失效
sentinel monitor mymaster 127.0.0.1 6379 2
// master 节点宕机多长时间才会被 sentinel 认为是失效
sentinel down-after-milliseconds mymaster 60000
sentinel failover-timeout mymaster 180000
sentinel parallel-syncs mymaster 1

sentinel monitor resque 192.168.1.3 6380 4
sentinel down-after-milliseconds resque 10000
sentinel failover-timeout resque 180000
// 在发生主备切换时最多可以有 5 个 slave 同时对新的 master 进行同步
sentinel parallel-syncs resque 5
~~~

Redis Sentinel 实现 Redis 集群高可用，只是在主从复制实现集群的基础下，多了一个 Sentinel 角色来帮助我们监控 Redis 节点的运行状态并自动实现故障转移。



当 master 节点出现故障的时候， Sentinel 会帮助我们实现故障转移，自动根据一定的规则选出一个 slave 升级为 master，确保整个 Redis 系统的可用性。整个过程完全自动，不需要人工介入。





### Sentinel 有什么作用

根据 [Redis Sentinel 官方文档](https://redis.io/topics/sentinel)的介绍，sentinel 节点主要可以提供 4 个功能：

●监控：监控所有 redis 节点（包括 sentinel 节点自身）的状态是否正常。
●故障转移：如果一个 master 出现故障，Sentinel 会帮助我们实现故障转移，自动将某一台 slave 升级为 master，确保整个 Redis 系统的可用性。
●通知 ：通知 slave 新的 master 连接信息，让它们执行 replicaof 成为新的 master 的 slave。
●配置提供 ：客户端连接 sentinel 请求 master 的地址，如果发生故障转移，sentinel 会通知新的 master 链接信息给客户端。

Redis Sentinel 本身设计的就是一个分布式系统，建议多个 sentinel 节点协作运行。这样做的好处是：

●多个 sentinel 节点通过投票的方式来确定 sentinel 节点是否真的不可用，避免误判（比如网络问题可能会导致误判）。
●Sentinel 自身就是高可用。

如果想要实现高可用，建议将哨兵 Sentinel 配置成单数且大于等于 3 台。

一个最简易的 Redis Sentinel 集群如下所示（官方文档中的一个例子），其中：

●M1 表示 master，R2、R3 表示 slave；
●S1、S2、S3 都是 sentinel；
●quorum 表示判定 master 失效最少需要的仲裁节点数。这里的值为 2 ，也就是说当有 2 个 sentinel 认为 master 失效时，master 才算真正失效。

如果 M1 出现问题，只要 S1、S2、S3 其中的两个投票赞同的话，就会开始故障转移工作，从 R2 或者 R3 中重新选出一个作为 master。

### Sentinel 如何检测节点是否下线

相关的问题：

●主观下线与客观下线的区别?
●Sentinel 是如何实现故障转移的？
●为什么建议部署多个 sentinel 节点（哨兵集群）？

Redis Sentinel 中有两个下线（Down）的概念：

●主观下线(SDOWN) ：sentinel 节点认为某个 Redis 节点已经下线了（主观下线），但还不是很确定，需要其他 sentinel 节点的投票。
●客观下线(ODOWN) ：法定数量（通常为过半）的 sentinel 节点认定某个 Redis 节点已经下线（客观下线），那它就算是真的下线了。

也就是说，主观下线 当前的 sentinel 自己认为节点宕机，客观下线是 sentinel 整体达成一致认为节点宕机。

每个 sentinel 节点以每秒钟一次的频率向整个集群中的 master、slave 以及其他 sentinel 节点发送一个 PING 命令。

如果对应的节点超过规定的时间（down-after-millseconds）没有进行有效回复的话，就会被其认定为是 主观下线(SDOWN) 。注意！这里的有效回复不一定是 PONG，可以是-LOADING 或者 -MASTERDOWN 。



如果被认定为主观下线的是 slave 的话， sentinel 不会做什么事情，因为 slave 下线对 Redis 集群的影响不大，Redis 集群对外正常提供服务。但如果是 master 被认定为主观下线就不一样了，sentinel 整体还要对其进行进一步核实，确保 master 是真的下线了。



所有 sentinel 节点要以每秒一次的频率确认 master 的确下线了，当法定数量（通常为过半）的 sentinel 节点认定 master 已经下线， master 才被判定为 客观下线(ODOWN) 。这样做的目的是为了防止误判，毕竟故障转移的开销还是比较大的，这也是为什么 Redis 官方推荐部署多个 sentinel 节点（哨兵集群）。



随后， sentinel 中会有一个 Leader 的角色来负责故障转移，也就是自动地从 slave 中选出一个新的 master 并执行完相关的一些工作(比如通知 slave 新的 master 连接信息，让它们执行 replicaof 成为新的 master 的 slave)。

如果没有足够数量的 sentinel 节点认定 master 已经下线的话，当 master 能对 sentinel 的 PING 命令进行有效回复之后，master 也就不再被认定为主观下线，回归正常。

### Sentinel 如何选择出新的master？

slave 必须是在线状态才能参加新的 master 的选举，筛选出所有在线的 slave 之后，通过下面 3 个维度进行最后的筛选（优先级依次降低）：



1slave 优先级 ：可以通过修改 slave-priority（redis.conf中配置，Redis5.0 后该配置属性名称被修改为 replica-priority） 配置的值来手动设置 slave 的优先级。slave-priority默认值为 100，其值越小得分越高，越有机会成为 master。比如说假设有三个优先级分别为 10,100,25 的 slave ，哨兵将选择优先级为 10 的。不过，0 是一个特殊的优先级值 ，如果一个 slave 的 slave-priority值为 0，代表其没有参加 master 选举的资格。如果没有优先级最高的，再判断复制进度。

2复制进度 ：Sentinel 总是希望选择出数据最完整（与旧 master 数据最接近）也就是复制进度最快的 slave 被提升为新的 master，复制进度越快得分也就越高。

3runid(运行 id) ：通常经过前面两轮筛选已经成功选出来了新的 master，万一真有多个 slave 的优先级和复制进度一样的话，那就 runid 小的成为新的 master，每个 redis 节点启动时都有一个 40 字节随机字符串作为运行 id。



  

### 如何从Sentinel集群中选择出 Leader？

我们前面说了，当 sentinel 集群确认有 master 客观下线了，就会开始故障转移流程，故障转移流程的第一步就是在 sentinel 集群选择一个 leader，让 leader 来负责完成故障转移。

如何选择出 Leader 角色呢？

这就需要用到分布式领域的 共识算法 了。简单来说，共识算法就是让分布式系统中的节点就一个问题达成共识。在 sentinel 选举 leader 这个场景下，这些 sentinel 要达成的共识就是谁才是 leader 。

大部分共识算法都是基于 Paxos 算法改进而来，在 sentinel 选举 leader 这个场景下使用的是 [Raft 算法](https://javaguide.cn/distributed-system/theorem&algorithm&protocol/raft-algorithm.html)。这是一个比 Paxos 算法更易理解和实现的共识算法—Raft 算法。更具体点来说，Raft 是 Multi-Paxos 的一个变种，其简化了 Multi-Paxos 的思想，变得更容易被理解以及工程实现。

对于学有余力并且想要深入了解 Raft 算法实践以及 sentinel 选举 leader 的详细过程的同学，推荐阅读下面这两篇文章：

●[Raft 算法详解](https://javaguide.cn/distributed-system/protocol/raft-algorithm.html)
●[Raft 协议实战之 Redis Sentinel 的选举 Leader 源码解析](https://cloud.tencent.com/developer/article/1021467)

### Sentinel 可以防止脑裂吗？

还是上面的例子，如果 M1 和 R2、R3 之间的网络被隔离，也就是发生了脑裂，M1 和 R2 、 R3 隔离在了两个不同的网络分区中。这意味着，R2 或者 R3 其中一个会被选为 master，这里假设为 R2。

但是！这样会出现问题了！！

如果客户端 C1 是和 M1 在一个网络分区的话，从网络被隔离到网络分区恢复这段时间，C1 写入 M1 的数据都会丢失，并且，C1 读取的可能也是过时的数据。这是因为当网络分区恢复之后，M1 将会成为 slave 节点。



想要解决这个问题的话也不难，对 Redis 主从复制进行配置即可。



下面对这两个配置进行解释：

●min-replicas-to-write 1：用于配置写 master 至少写入的 slave 数量，设置为 0 表示关闭该功能。3 个节点的情况下，可以配置为 1 ，表示 master 必须写入至少 1 个 slave ，否则就停止接受新的写入命令请求。
●min-replicas-max-lag 10 ：用于配置 master 多长时间（秒）无法得到从节点的响应，就认为这个节点失联。我们这里配置的是 10 秒，也就是说 master 10 秒都得不到一个从节点的响应，就会认为这个从节点失联，停止接受新的写入命令请求。

不过，这样配置会降低 Redis 服务的整体可用性，如果 2 个 slave 都挂掉，master 将会停止接受新的写入命令请求。

## Redis Cluster集群（缓存的数据量太大怎么办）

建议带着下面这些重要的问题（面试常问）阅读：

●为什么需要 Redis Cluster？解决了什么问题？有什么优势？
●Redis Cluster 是如何分片的？
●为什么 Redis Cluster 的哈希槽是 16384 个?
●如何确定给定 key 的应该分布到哪个哈希槽中？
●Redis Cluster 支持重新分配哈希槽吗？
●Redis Cluster 扩容缩容期间可以提供服务吗？
●Redis Cluster 中的节点是怎么进行通信的？

### 为什么需要Redis Cluster

高并发场景下，使用 Redis 主要会遇到的两个问题：

1. **缓存的数据量太大** ：实际缓存的数据量可以达到几十 G，甚至是成百上千 G；
2. **并发量要求太大** ：虽然 Redis 号称单机可以支持 10w 并发，但实际项目中，不可靠因素太多，就比如一些复杂的写/读操作就可能会让这个并发量大打折扣。而且，就算真的可以实际支持 10w 并发，达到瓶颈了，可能也没办法满足系统的实际需求。

主从复制和 Redis Sentinel 这两种方案本质都是通过增加主库（master）的副本（slave）数量的方式来提高 Redis 服务的整体可用性和读吞吐量，都不支持横向扩展来缓解写压力以及解决缓存数据量过大的问题。



对于这两种方案来说，如果写压力太大或者缓存数据量太大的话，我们可以考虑提高服务器硬件的配置。不过，提高硬件配置成本太高，能力有限，无法动态扩容缩容，局限性太大。从本质上来说，靠堆硬件配置的方式并没有实质性地解决问题，依然无法满足高并发场景下分布式缓存的要求。



通常情况下，更建议使用 **Redis 切片集群** 这种方案，更能满足高并发场景下分布式缓存的要求。



简单来说，**Redis 切片集群** 就是部署多台 Redis 主节点（master），这些节点之间平等，并没有主从之说，同时对外提供读/写服务。缓存的数据库相对均匀地分布在这些 Redis 实例上，客户端的请求通过路由规则转发到目标 master 上。



为了保障集群整体的高可用，我们需要保证集群中每一个 master 的高可用，可以通过主从复制给每个 master 配置一个或者多个从节点（slave）。







Redis 切片集群对于横向扩展非常友好，只需要增加 Redis 节点到集群中即可。



在 Redis 3.0 之前，我们通常使用的是 [Twemproxy](https://github.com/twitter/twemproxy)、[Codis](https://github.com/CodisLabs/codis) 这类开源分片集群方案。Twemproxy、Codis 就相当于是上面的 Proxy 层，负责维护路由规则，实现负载均衡。



不过，Twemproxy、Codis 虽然未被淘汰，但官方已经没有继续维护了。

到了 Redis 3.0 的时候，Redis 官方推出了分片集群解决方案 [Redis Cluster](https://redis.io/topics/cluster-tutorial) 。经过多个版本的持续完善，Redis Cluster 成为 Redis 切片集群的首选方案，满足绝大部分高并发业务场景需求。

Redis Cluster 通过 分片（Sharding） 来进行数据管理，提供 主从复制（Master-Slave Replication）、故障转移（Failover） 等开箱即用的功能，可以非常方便地帮助我们解决 Redis 大数据量缓存以及 Redis 服务高可用的问题。

Redis Cluster 这种方案可以很方便地进行 横向拓展（Scale Out），内置了开箱即用的解决方案。当 Redis Cluster 的处理能力达到瓶颈无法满足系统要求的时候，直接动态添加 Redis 节点到集群中即可。根据官方文档中的介绍，Redis Cluster 支持扩展到 1000 个节点。反之，当 Redis Cluster 的处理能力远远满足系统要求，同样可以动态删除集群中 Redis 节点，节省资源。

可以说，Redis Cluster 的动态扩容和缩容是其最大的优势。

虽说 Redis Cluster 可以扩展到 1000 个节点，但强烈不推荐这样做，应尽量避免集群中的节点过多。这是因为 Redis Cluster 中的各个节点基于 Gossip 协议 来进行通信共享信息，当节点过多时，Gossip 协议的效率会显著下降，通信成本剧增。

最后，总结一下 Redis Cluster 的主要优势：



- 可以横向扩展缓解写压力和存储压力，支持动态扩容和缩容；
- 具备主从复制、故障转移（内置了 Sentinel 机制，无需单独部署 Sentinel 集群）等开箱即用的功能。

### 一个最基本的Redis Cluster架构是怎样的？

为了保证高可用，Redis Cluster 至少需要 3 个 master 以及 3 个 slave，也就是说每个 master 必须有 1 个 slave。master 和 slave 之间做主从复制，slave 会实时同步 master 上的数据。

不同于普通的 Redis 主从架构，这里的 slave 不对外提供读服务，主要用来保障 master 的高可用，当 master 出现故障的时候替代它。



如果 master 只有一个 slave 的话，master 宕机之后就直接使用这个 slave 替代 master 继续提供服务。假设 master1 出现故障，slave1 会直接替代 master1，保证 Redis Cluster 的高可用。

如果 master 有多个 slave 的话，Redis Cluster 中的其他节点会从这个 master 的所有 slave 中选出一个替代 master 继续提供服务。Redis Cluster 总是希望数据最完整的 slave 被提升为新的 master。

Redis Cluster 是去中心化的（各个节点基于 Gossip 进行通信），任何一个 master 出现故障，其它的 master 节点不受影响，因为 key 找的是哈希槽而不是 Redis 节点。不过，Redis Cluster 至少要保证宕机的 master 有一个 slave 可用。

如果宕机的 master 无 slave 的话，为了保障集群的完整性，保证所有的哈希槽都指派给了可用的 master ，整个集群将不可用。这种情况下，还是想让集群保持可用的话，可以将cluster-require-full-coverage 这个参数设置成 no，cluster-require-full-coverage 表示需要 16384 个 slot 都正常被分配的时候 Redis Cluster 才可以对外提供服务。

如果我们想要添加新的节点比如 master4、master5 进入 Redis Cluster 也非常方便，只需要重新分配哈希槽即可。



如果我们想要移除某个 master 节点的话，需要先将该节点的哈希槽移动到其他节点上，这样才可以进行删除，不然会报错。

### Redis Cluster是如何分片的

类似的问题：

●Redis Cluster 中的数据是如何分布的？
●如何确定给定 key 的应该分布到哪个哈希槽中？

Redis Cluster 并没有使用一致性哈希，采用的是 哈希槽分区 ，每一个键值对都属于一个 hash slot（哈希槽） 。

Redis Cluster 通常有 16384 个哈希槽 ，要计算给定 key 应该分布到哪个哈希槽中，我们只需要先对每个 key 计算 CRC-16（XMODEM） 校验码，然后再对这个校验码对 16384(哈希槽的总数) 取模，得到的值即是 key 对应的哈希槽。

哈希槽的计算公式如下：





创建并初始化 Redis Cluster 的时候，Redis 会自动平均分配这 16384 个哈希槽到各个节点，不需要我们手动分配。如果你想自己手动调整的话，Redis Cluster 也内置了相关的命令比如 ADDSLOTS、ADDSLOTSRANGE（后面会详细介绍到重新分配哈希槽相关的命令）。

假设集群有 3 个 Redis 节点组成，每个节点负责整个集群的一部分数据，哈希槽可能是这样分配的（这里只是演示，实际效果可能会有差异）：

●Node 1 ： 0 - 5500 的 hash slots
●Node 2 ： 5501 - 11000 的 hash slots
●Node 3 ： 11001 - 16383 的 hash slots

在任意一个 master 节点上执行 CLUSTER SLOTS命令即可返回哈希槽和节点的映射关系:



客户端连接 Redis Cluster 中任意一个 master 节点即可访问 Redis Cluster 的数据，当客户端发送命令请求的时候，需要先根据 key 通过上面的计算公示找到的对应的哈希槽，然后再查询哈希槽和节点的映射关系，即可找到目标节点。



如果哈希槽确实是当前节点负责，那就直接响应客户端的请求返回结果，如果不由当前节点负责，就会返回 -MOVED 重定向错误，告知客户端当前哈希槽是由哪个节点负责，客户端向目标节点发送请求并更新缓存的哈希槽分配信息。



这个时候你可能就会疑问：为什么还会存在找错节点的情况呢？根据公式计算难道还会出错？



这是因为 Redis Cluster 内部可能会重新分配哈希槽比如扩容缩容的时候（后文中有详细介绍到 Redis Cluster 的扩容和缩容问题），这就可能会导致客户端缓存的哈希槽分配信息会有误。



从上面的介绍中，我们可以简单总结出 Redis Cluster 哈希槽分区机制的优点：解耦了数据和节点之间的关系，提升了集群的横向扩展性和容错性。



### 为什么Redis Cluster的哈希槽是16384个

CRC16 算法产生的校验码有 16 位，理论上可以产生 65536（2^16，0 ~ 65535）个值。为什么 Redis Cluster 的哈希槽偏偏选择的是 16384（2^14）个呢？

2015 年的时候，在 Redis 项目的 issues 区，已经有人提了类似的问题，地址：https://github.com/redis/redis/issues/2576。Redis 作者 antirez 巨佬本人专门对这个问题进行了回复。



antirez 认为哈希槽是 16384（2 的 14 次方） 个的原因是：

●正常的心跳包会携带一个节点的完整配置，它会以幂等的方式更新旧的配置，这意味着心跳包会附带当前节点的负责的哈希槽的信息。假设哈希槽采用 16384 ,则占空间 2k(16384/8)。假设哈希槽采用 65536， 则占空间 8k(65536/8)，这是令人难以接受的内存占用。
●由于其他设计上的权衡，Redis Cluster 不太可能扩展到超过 1000 个主节点。

也就是说，65536 个固然可以确保每个主节点有足够的哈希槽，但其占用的空间太大。而且，Redis Cluster 的主节点通常不会扩展太多，16384 个哈希槽完全足够用了。

cluster.h 文件中定义了消息结构 clusterMsg（源码地址：https://github.com/redis/redis/blob/7.0/src/cluster.h） ：



myslots 字段用于存储哈希槽信息， 属于无符号类型的 char 数组，数组长度为 16384/8 = 2048。C 语言中的 char 只占用一个字节，而 Java 语言中 char 占用两个字节，小伙伴们不要搞混了。

这里实际就是通过 bitmap 这种数据结构维护的哈希槽信息，每一个 bit 代表一个哈希槽，每个 bit 只能存储 0/1 。如果该位为 1，表示这个哈希槽是属于这个节点。



消息传输过程中，会对 myslots 进行压缩，bitmap 的填充率越低，压缩率越高。bitmap 的填充率的值是 哈希槽总数/节点数 ，如果哈希槽总数太大的话，bitmap 的填充率的值也会比较大。

最后，总结一下 Redis Cluster 的哈希槽的数量选择 16384 而不是 65536 的主要原因：

●哈希槽太大会导致心跳包太大，消耗太多带宽；
●哈希槽总数越少，对存储哈希槽信息的 bitmap 压缩效果越好；
●Redis Cluster 的主节点通常不会扩展太多，16384 个哈希槽已经足够用了。

### Redis Cluster如何重新分配哈希槽

如果你想自己手动调整的话，Redis Cluster 也内置了相关的命令：

●CLUSTER ADDSLOTS slot [slot ...] : 把一组 hash slots 分配给接收命令的节点，时间复杂度为 O(N)，其中 N 是 hash slot 的总数；
●CLUSTER ADDSLOTSRANGE start-slot end-slot [start-slot end-slot ...] （Redis 7.0 后新加的命令）： 把指定范围的 hash slots 分配给接收命令的节点，类似于 ADDSLOTS 命令，时间复杂度为 O(N) 其中 N 是起始 hash slot 和结束 hash slot 之间的 hash slot 的总数。
●CLUSTER DELSLOTS slot [slot ...] : 从接收命令的节点中删除一组 hash slots；
●CLUSTER FLUSHSLOTS ：移除接受命令的节点中的所有 hash slot；
●CLUSTER SETSLOT slot MIGRATING node-id： 迁移接受命令的节点的指定 hash slot 到目标节点（node_id 指定）中；
●CLUSTER SETSLOT slot IMPORTING node-id： 将目标节点（node_id 指定）中的指定 hash slot 迁移到接受命令的节点中；
●......

简单演示一下:



### Redis Cluster扩容缩容期间可以提供服务吗

类似的问题：

●如果客户端访问的 key 所属的槽正在迁移怎么办？
●如何确定给定 key 的应该分布到哪个哈希槽中？



Redis Cluster 扩容和缩容本质是进行重新分片，动态迁移哈希槽。



为了保证 Redis Cluster 在扩容和缩容期间依然能够对外正常提供服务，Redis Cluster 提供了重定向机制，两种不同的类型：



●ASK 重定向 ：可以看做是临时重定向，后续查询仍然发送到旧节点。

●MOVED 重定向 ：可以看做是永久重定向，后续查询发送到新节点。



客户端向指定节点发送请求命令，从客户端的角度来看，ASK 重定向是下面这样的：



1如果请求的 key 对应的哈希槽还在当前节点的话，就直接响应客户端的请求。

2如果请求的 key 对应的哈希槽在迁移过程中，但是请求的 key 还未迁移走的话，说明当前节点任然可以处理当前请求，同样可以直接响应客户端的请求。

3如果客户端请求的 key 对应的哈希槽当前正在迁移至新的节点且请求的 key  已经被迁移走的话，就会返回 -ASK 重定向错误，告知客户端要将请求发送到哈希槽被迁移到的目标节点。 -ASK 重定向错误信息中包含请求 key 迁移到的新节点的信息。

4客户端收到 -ASK 重定向错误后，将会临时（一次性）重定向，自动向新节点发送一条 [ASKING](https://redis.io/commands/asking/) 命令。也就是说，接收到 ASKING 命令的节点会强制执行一次请求，下次再来需要重新提前发送 ASKING 命令。

5新节点在收到 ASKING 命令后可能会返回重试错误（TRYAGAIN），因为可能存在当前请求的 key 还在导入中但未导入完成的情况。

6客户端发送真正需要请求的命令。

7ASK 重定向并不会同步更新客户端缓存的哈希槽分配信息，也就是说，客户端对正在迁移的相同哈希槽的请求依然会发送到旧节点而不是新节点。



如果客户端请求的 key 对应的哈希槽已经迁移完成的话，就会返回 -MOVED 重定向错误，告知客户端当前哈希槽是由哪个节点负责，客户端向新节点发送请求并更新缓存的哈希槽分配信息，后续查询将被发送到新节点。

### Redis Cluster中的节点是怎么进行通信的

Redis Cluster 是一个典型的分布式系统，分布式系统中的各个节点需要互相通信。既然要相互通信就要遵循一致的通信协议，Redis Cluster 中的各个节点基于 Gossip 协议 来进行通信共享信息，每个 Redis 节点都维护了一份集群的状态信息。

Redis Cluster 的节点之间会相互发送多种 Gossip 消息：

●MEET ：在 Redis Cluster 中的某个 Redis 节点上执行 CLUSTER MEET ip port 命令，可以向指定的 Redis 节点发送一条 MEET 信息，用于将其添加进 Redis Cluster 成为新的 Redis 节点。
●PING/PONG ：Redis Cluster 中的节点都会定时地向其他节点发送 PING 消息，来交换各个节点状态信息，检查各个节点状态，包括在线状态、疑似下线状态 PFAIL 和已下线状态 FAIL。
●FAIL ：Redis Cluster 中的节点 A 发现 B 节点 PFAIL ，并且在下线报告的有效期限内集群中半数以上的节点将 B 节点标记为 PFAIL，节点 A 就会向集群广播一条 FAIL 消息，通知其他节点将故障节点 B 标记为 FAIL 。
●......

有了 Redis Cluster 之后，不需要专门部署 Sentinel 集群服务了。Redis Cluster 相当于是内置了 Sentinel 机制，Redis Cluster 内部的各个 Redis 节点通过 Gossip 协议互相探测健康状态，在故障时可以自动切换。

cluster.h 文件中定义了所有的消息类型（源码地址：https://github.com/redis/redis/blob/7.0/src/cluster.h） 。Redis 3.0 版本的时候只有 9 种消息类型，到了 7.0 版本的时候已经有 11 种消息类型了。



## redis分布式怎么做 知道哨兵吗

## 介绍下集群cluster

主从复制和哨兵都是为了提高可用性，不是为了缓解缓存数据量过大的问题

redis切片集群  缓解压力

Redis 切片集群 就是部署多台 Redis 主节点（master），这些节点之间平等，并没有主从之说，同时对外提供读/写服务。缓存的数据库相对均匀地分布在这些 Redis 实例上，客户端的请求通过路由规则转发到目标 master 上。

## 3.redis 用的什么模式

单机模式 （有单机 主从 哨兵 集群

## 4.哨兵模式和集群模式的区别

## 5.哪一个支持的并发度更高

## 分片集群

## 哨兵机制

## redis怎么做主从，集群
