# 日常实习-Mysql面试题

增加一行

# 基础

### --数据库三范式

第一范式：强调的是**列的原子性**，即数据库表的每一列都是不可分割的原子数据项。
第二范式：要求实体的属性完全依赖于主关键字。所谓完全 依赖是指不能存在仅依赖主关键字一部分的属性。
第三范式：任何非主属性不依赖于其它非主属性。

---

**第一范式：数据库表的每一列都是不可分割的基本数据项（原子性）**
**第二范式：要求实体的属性完全依赖于主关键字**
**第三范式：一个数据库表中不包含已在其它表中已包含的非主关键字信息**

---



所谓第一范式 (1NF) 是指在关系模型中，对于添加列的一个规范要求，所有的列都应该是原子性的，即数据库表的每一列都是不可分割的原子数据项，而不能是集合数组，记录等非原子数据项。即实体中的某个属性有多个值时，必须拆分为不同的属性。在符合第一范式 (1NF) 表中的每个域值只能是实体的一个属性或一个属性的一部分。简而言之，第一范式就是无重复的域。
比如地址，我们可以存为辽宁省大连市甘井子区。那么这样其实就不满足，因为我们把省市区放在一起存储了。我们将地址进行拆分存储即可。省，市，区。这样才满足第一范式。

第二范式 (2NF) 是在第一范式 (1NF) 的基础上建立起来的，即满足第二范式 (2NF)必须先满足第一范式 (1NF) 。第二范式 (2NF) 要求数据库表中的每个实例或记录必须可以被唯一地区分。选取一个能区分每个实体的属性或属性组，作为实体的唯一标识
比如说我们有需要存储用户和权限。如果说我们用用户的id和角色的id作为主键，也是可以进行存储的。这样的问题就是，其中的任意一个信息，并不是和主键完全相关的。如果将用户id和角色id分别拆分为两个表。然后用一个中间表关联，这样是符合第二范式的。

第三范式 (3NF) 是第二范式 (2NF) 的一个子集，即满足第三范式 (3NF) 必须满足第二范式 (2NF) 。简而言之，第三范式 (3NF) 要求一个关系中不包含已在其它关系已包含的非主关键字信息。例如，存在一个部门信息表，其中每个部门有部门编号(dept_id) 、部门名称、部门简介等信息。那么在员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果加入就会有大量的数据冗余。简而言之，第三范式就是属性不依赖于其它非主属性，也就是在满足2NF的基础上，任何非主属性不得传递依赖于主属性

### --主键、外键

主键：数据库表中对储存数据对象予以**唯一和完整标识**的数据列或属性的组合。一个数据列只能有一个主键，且主键的取值不能缺失，即不能为空值（Null）。 非空非重复

外键：在一个表中存在另一个表的主键称此表的

### --mysql约束

NOT NULL

UNIQUE

PRIMARY KEY

FOREIGN KEY

CHECK

---

NOT NULL: 用于控制字段的内容一定不能为空（NULL）。
UNIQUE: 控件字段内容不能重复，一个表允许有多个 Unique 约束。
PRIMARY KEY: 也是用于控件字段内容不能重复，但它在一个表只允许出现一个。
FOREIGN KEY: 用于预防破坏表之间连接的动作，也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。

>数据库外键（Foreign Key)是关系型数据库的一个重要概念，它用于建立表与表之间的关系，以保证数据的完整性和一致性。
>
>外键是指一个表中的一个或多个字段，它们的值必须在另一个表中的某个字段中存在。这个被参照的表中的字段通常是主键（Primary Key），这样就可以通过外键将两个表关联起来。
>
>举个例子，假设有两个表，一个是订单表，一个是客户表。订单表中有一个字段是客户ID，这个字段就可以作为外键，参照客户表中的客户ID字段。这样，当我们在订单表中插入一条数据时，就必须保证这个客户ID在客户表中已经存在，否则就会出现数据不一致的问题。
>
>外键的作用是保证数据的完整性和一致性。通过外键，我们可以将多个表关联起来，从而避免数据重复和冗余。同时，外键也可以限制数据的删除和修改，以避免对关联表中的数据造成影响。
>
>需要注意的是，外键的使用需要谨慎，因为它会对数据库的性能产生影响。在设计数据库时，应该根据实际情况来选择是否使用外键，以及如何使用外键。
>
>

一个表中的 FOREIGN KEY 指向另一个表中的 UNIQUE KEY(唯一约束的键)。

FOREIGN KEY 约束用于预防破坏表之间连接的行为。

FOREIGN KEY 约束也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。

CHECK: 用于控制字段的值范围。







### --存储过程

预编译的一组sql语句



## 建表的时候有没有哪些问题，注意事项

基本设计规范

	1引擎使用InnoDB
	
	2数据库和表字符集统一UTF8
	
	3表和字段都要添加注释
	
	4

字段设计规范



索引设计规范





## 数据库设计一个表考虑哪些因素



## 怎样提升MySQL查找效率？索引，然后问了我一些索引相关的，后面跟我说知不知道哈希索引这些，我说没太了解。



## 有哪些引擎（MySQL有哪些存储引擎

InnoDB,MyISAM是5.5前，BDB,memory

**存储引擎是基于表而不是数据库**

## 这些存储引擎有什么区别

见myisam innodb区别

## 14. MyISAM有什么优势

速度快

## mysql的存储引擎，手机号在数据库中定义成什么类型比较合适

Innodb

手机号长度固定，应该用固定长度varchar存储

## 底层数据结构

Innodb底层存储结构是B+树

MyISAM静态索引结构

## InnoDB,MyISAM区别

1是否支持**行级锁**

2是否支持**事务**

3是否是否支持**外键约束** 要求它的值在另一个表的某个字段中存在（订单表中有一个字段是客户ID，这个字段就可以作为外键，参照客户表中的客户ID字段。

4索引实现不一样  **MyISAM索引文件和数据文件是分离的**

在InnoDB中，数据和索引文件是合起来储存的，MyISAM索引文件和数据文件是分离的(非聚集)，并且主键索引和辅助索引（二级索引）的储存方式是一样的。

InnoDB中索引文件和数据文件是同一个文件（聚集），并且主键索引和二级索引储存方式有所不同，如图所示，二级索引的叶子节点不储存数据，仅储存主键ID。

## 日常工作中SQL优化

1加索引

   增加索引是一种简单高效的手段，但是需要选择合适的列，同时避免导致索引失效的操作，比如like、函数等

2、避免返回不必要的数据列，减少返回的数据列可以增加查询的效率

3.根据查询分析器适当优化SQL的结构，比如是否走全表扫描、避免子查询等

4分库分表 单表数据量大的情况

5.读写分离  读多写少场景

## 有一条sql语句执行很慢，怎么排查问题



## 查询优化



## MySQL优化，怎么优化慢查询



## 平常有做过什么sql优化吗，常见的调优手段？

## 27、用过sql执行计划吗？explain。

做一些慢查询优化的东西。(从重点关注的四个字段段说了起来)



## --执行一条select语句，期间发生了什么

~~~mysql
// 在 product 表中，查询 id = 1 的记录
select * from product where id = 1;
~~~

## MySQL 执行一条SQL查询语句流程是怎样的？

下面就是 MySQL 执行一条 SQL 查询语句的流程，看到mysql内部各个功能模块![查询语句执行流程](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292142588.png)

Mysql架构分  server层和存储引擎层



### 第一步：连接器

- 与客户端进行 TCP 三次握手建立连接；
- 校验客户端的用户名和密码，如果用户名或密码不对，则会报错；
- 如果用户名和密码都对了，会读取该用户的权限，然后后面的权限逻辑判断都基于此时读取到的权限

### 第二步:查询缓存

如果 SQL 是查询语句（select 语句），MySQL 就会先去查询缓存（ Query Cache ）里查找缓存数据，看看之前有没有执行过这一条命令，这个查询缓存是以 key-value 形式保存在内存中的，key 为 SQL 查询语句，value 为 SQL 语句查询的结果。

8.0版本删除这一步  

> 这里说的查询缓存是 server 层的，也就是 MySQL 8.0 版本移除的是 server 层的查询缓存，并不是 Innodb 存储引擎中的 buffer pool。

### 第三步：解析SQL

解析器对sql语句解析

解析器只负责构建语法树和检查语法

下个阶段检测表和字段是否存在

### 第四步：执行SQL

- 预处理阶段
- 优化阶段
- 执行阶段

#### 预处理器

- 检查 SQL 查询语句中的表或者字段是否存在；
- 将 `select *` 中的 `*` 符号，扩展为表上的所有列；

#### 优化器

优化器 为 SQL 查询语句先制定一个执行计划；

**优化器主要负责将 SQL 查询语句的执行方案确定下来**

比如在表里面有多个索引的时候，优化器会基于查询成本的考虑，来决定选择使用哪个索引。

> 要想知道优化器选择了哪个索引，我们可以在查询语句最前面加个 `explain` 命令，这样就会输出这条 SQL 语句的执行计划，然后执行计划中的 key 就表示执行过程中使用了哪个索引；key是null标识没有使用索引，会全表扫描。

#### 执行器

执行器和存储引擎交互，以记录为单位。



### 总结

- 连接器：建立连接，管理连接、校验用户身份；
- 查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执行。MySQL 8.0 已删除该模块；
- 解析 SQL，通过解析器对 SQL 查询语句进行词法分析、语法分析，然后构建语法树，方便后续模块读取表名、字段、语句类型；
- 执行 SQL：执行 SQL 共有三个阶段：
  - 预处理阶段：检查表或字段是否存在；将 `select *` 中的 `*` 符号扩展为表上的所有列。
  - 优化阶段：基于查询成本的考虑， 选择查询成本最小的执行计划；
  - 执行阶段：根据执行计划执行 SQL 查询语句，从存储引擎读取记录，返回给客户端；



# 索引

## 索引概念（什么是索引

是一种**快速查询和检索数据**的数据结构，

可以提高Mysql的检索速度，相当于目录，

索引是一种文件，包含数据表记录的引用指针，需要占据物理空间；

mysql，Innodb MyISAM使用B+树作为数据结构

## 索引的优缺点

优点

- 加快数据检索速度
- 创建唯一性索引可以保证数据库表每一行数据的唯一性
- 使用索引在查询的过程中，使用优化隐藏器，提高性能

缺点

- 时间；**创建和维护**索引要消耗时间，数据增删改也要给索引动态修改，降低SQL效率
- 空间；索引需要物理文件存储 耗费空间

## 什么时候需要/不需要创建索引（不适合建索引

需要：

- 字段有**唯一性**限制的，比如商品编码；
- **经常用于 `WHERE` 查询条件的字段**，这样能够提高整个表的查询速度，如果查询条件不是一个字段，可以建立联合索引。
- **经常用于 `GROUP BY` 和 `ORDER BY` 的字段**，这样在查询的时候就不需要再去做一次排序了，因为我们都已经知道了建立索引之后在 B+Tree 中的记录都是排序好的。

不需要

- **`WHERE` 条件，`GROUP BY`，`ORDER BY` 里用不到的字段**，索引的价值是快速定位，如果起不到定位的字段通常是不需要创建索引的，因为索引是会占用物理空间的。
- **字段中存在大量重复数据，不需要创建索引**，比如性别字段，只有男女，如果数据库表中，男女的记录分布均匀，那么无论搜索哪个值都可能得到一半的数据。在这些情况下，还不如不要索引，因为 MySQL 还有一个查询优化器，查询优化器发现某个值出现在表的数据行中的百分比很高的时候，它一般会忽略索引，进行全表扫描。
- **表数据太少的时候，不需要创建索引**；
- **经常更新的字段不用创建索引**，比如不要对电商项目的用户余额建立索引，因为索引字段频繁修改，由于要维护 B+Tree的有序性，那么就需要频繁的重建索引，这个过程是会影响数据库性能的

## 建索引一般不建议怎么做

同 不需要建立索引的条件

where orderby groupby用不到

大量重复

数据太少

经常更新

## mysql有哪几种索引类型（索引类型总结

四个角度

- 数据结构: B+tree索引、Hash索引、Full-text全文索引。
- 物理存储 聚族索引（聚集索引）、二级索引（非聚集索引）；主键索引属于聚簇索引，二级索引（辅助索引）属于非聚簇索引
- 字段特性 主键索引、唯一索引、普通索引、前缀索引、全文索引
- 字段个数  单列索引、联合索引

## 主键索引与非主键索引

主键列使用主键索引

一张数据表有只能有一个主键，并且主键不能为 null，不能重复。

> 在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引且不允许存在 null 值的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键。

二级索引=非主键索引

二级索引的叶子节点存储的数据是主键。通过二级索引定位主键的位置

唯一索引，普通索引，前缀索引等索引属于二级索引。

区别：

- 主键索引的 B+Tree 的叶子节点存放的是实际数据，所有完整的用户记录都存放在主键索引的 B+Tree 的叶子节点里；
- 二级索引的 B+Tree 的叶子节点存放的是主键值，而不是实际数据。
- 二级索引不一定回表

(Innodb 下 ，叶子节点存放的区别 ，是否会产生回表 这两个角度说了

---

> **唯一索引(Unique Key)**：唯一索引也是一种约束。**唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。** 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。
>
> **普通索引(Index)**：**普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。**
>
> **前缀索引(Prefix)**：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。
>
> **全文索引(Full Text)**：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术

## 非聚簇索引和聚簇索引的区别

聚簇索引：数据和索引结构一起存放，不是一种单独的索引类型；Innodb中的主键索引就是聚簇索引

优点

1查询速度非常快

2对排序查找和范围查找优化

缺点

1依赖于有序的数据

2更新代价大

非聚簇索引（非聚集索引）

索引结构和数据分开存放的索引，并不是一种单独的索引类型。二级索引(辅助索引)就属于非聚簇索引。

非聚簇索引的叶子节点并不一定存放数据的指针，因为二级索引的叶子节点就存放的是主键，根据主键再回表查数据。

优点

更新代价比聚簇索引小

缺点

1依赖于有序的数据

2可能二次查询（回表）

![聚簇索引和非聚簇索引](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292142402.png)

区别：

- 叶子节点存储 表的数据/该列对应的主键（行号）
- 查询是否需要回表：非聚簇根据主键再去聚簇索引查找数据
- 通常情况聚簇索引查询只会查一次，对应非：多次

MyISAM 主键/二级都是非聚簇索引  Innodb主->聚簇  二级->非聚簇

## --非聚簇索引一定回表吗

不一定 根据名字建立索引 只查询名字

查到名字就返回即可

## --覆盖索引

覆盖索引：如果一个索引包含（或者说覆盖）所有需要查询的字段的值，直接根据索引查到数据，不用回表

>  InnoDB 存储引擎中，如果不是主键索引，叶子节点存储的是主键+列值

## 联合索引

使用表中的多个字段创建索引，就是 **联合索引**，也叫 **组合索引** 或 **复合索引**。

~~~mysql
ALTER TABLE `cus_order` ADD INDEX id_score_name(score, name);

~~~

## 最左前缀匹配原则

最左前缀匹配原则指的是，在使用联合索引时，**MySQL** 会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配，如果查询条件中存在与联合索引中最左侧字段相匹配的字段，则就会使用该字段过滤一批数据，直至联合索引中全部字段匹配完成，或者在执行过程中遇到**范围查询**（如 **`>`**、**`<`**）才会停止匹配。

对于 **`>=`**、**`<=`**、**`BETWEEN`**、**`like`** 前缀匹配的范围查询，并不会停止匹配。所以，我们在使用联合索引时，可以将区分度高的字段放在最左边，这也可以过滤更多数据。

`a > 1 and b = 2`只有a用到索引

`a>=1 and b=2` a b都用到了索引 

**要根据索引的顺序来where字段查询**

eg:

联合索引`(product_no, name)`

B+树按product_no作比较，相同再比较name

也就是说，联合索引查询的 B+Tree 是先按 product_no 进行排序，然后再 product_no 相同的情况再按 name 字段排序。

因此，使用联合索引时，存在**最左匹配原则**，也就是按照最左优先的方式进行索引的匹配。在使用联合索引进行查询的时候，如果不遵循「最左匹配原则」，联合索引会失效，这样就无法利用到索引快速查询的特性了。

比如，如果创建了一个 `(a, b, c)` 联合索引，如果查询条件是以下这几种，就可以匹配上联合索引：

- where a=1；
- where a=1 and b=2 and c=3；
- where a=1 and b=2；

需要注意的是，因为有查询优化器，所以 a 字段在 where 子句的顺序并不重要。

但是，如果查询条件是以下这几种，因为不符合最左匹配原则，所以就无法匹配上联合索引，联合索引就会失效:

- where b=2；
- where c=3；
- where b=2 and c=3；

上面这些查询条件之所以会失效，是因为`(a, b, c)` 联合索引，是先按 a 排序，在 a 相同的情况再按 b 排序，在 b 相同的情况再按 c 排序。所以，**b 和 c 是全局无序，局部相对有序的**，这样在没有遵循最左匹配原则的情况下，是无法利用到索引的。

只有a相同的情况下，b才是有序

## 联合索引问题，(a,b,c)建索引，where a=? and b=? and c=? order by b，会走这个联合索引么？

（蒙的不会,后面查资料group by order by也是遵循最左匹配原则，说错了淦。[https://www.cnblogs.com/ttaylor/p/14443815.html](https://hd.nowcoder.com/link.html?target=https://www.cnblogs.com/ttaylor/p/14443815.html)）

## --前缀索引

前缀索引：字符类型字段的前几个字符建立的索引，而不是在整个字段上建立的索引，前缀索引可以建立在字段类型为 char、 varchar、binary、varbinary 的列上。





## MySQL索引有哪些数据结构

Hash表 

B+树

## innodb的索引结构

B+树

## mysql的innodb底层数据结构为什么用B+树

hash不支持排序，不支持顺序和范围查询

BST 性能非常依赖于它的平衡程度

AVL  1频繁旋转 保持平衡，降低查询性能；2一个节点只存一个数据 需要多次IO，数据库索引应该最大限度减少IO次数

红黑树 平衡性较弱 可能多次IO才能查询到

> 每个节点非红即黑；
>
> 根节点总是黑色的；
>
> 每个叶子节点都是黑色的空节点（NIL 节点）；
>
> 如果节点是红色的，则它的子节点必须是黑色的（反之不一定）；
>
> 从根节点到叶节点或空子节点的每条路径，必须包含相同数目的黑色节点（即相同的黑色高度）

B-树=B树 所有节点都存放数据 且叶子节点没有指向相邻节点的引用链

B+树范围查询只需要对叶子节点链表遍历

B+树与 B 树相比，具备更少的 IO 次数、更稳定的查询效率和更适于范围查询这些优势。

**B和B+对比**

B：

1 叶节点具有相同的深度，叶节点的指针为空；

2 所有索引元素不重复；

3 节点中的数据索引从左到右递增排列。

B+

1 非叶子节点不存储data，只存储索引(冗余)，可以放更多的索引，一次IO读取的结点更多；

2 叶子节点包含所有索引字段；

3 叶子节点用指针连接，提高区间访问的性能。 B+叶子节点天然排序



![image-20230704144243930](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292142398.png)

---

**B+Tree 相比于 B 树和二叉树来说，最大的优势在于查询效率很高，因为即使在数据量很大的情况，查询一个数据的磁盘 I/O 依然维持在 3-4次。**



## 用过索引吗？

用过 辅助索引、 联合索引。

## 24、添加索引的原则。

(where、range。。。)

## mysql索引的查询耗时主要在哪里



## MySQL索引有哪些数据结构

索引底层常用数据结构 B+，B，Hash，红黑；

Mysql中B+树和哈希表，B+树常用

## `B+`树和`B`树什么区别？

## mysql索引的B+树一般设计成几层



## Mysql的索引结构？优点啥啥的



## 根据范围查找时B+树对比B树



## 什么情况下不走索引

数据量不大时全表扫描也可



## 索引失效的情况

七字口诀  模型数空运最快

**模糊查询**中like 以%开头

数据类型错误 也失效 对索引列类型转换

对索引字段使用**内部函数**

如果 不限制索引列NOT NULL 数据库不按照索引计算 

加减乘除等运算

最左原则，复合索引中 索引列顺序最左

全表扫描更快就不用索引

没有使用索引列作为where子句的查询条件

查询条件中包括 or

查询大量数据的时候 可能不会使用索引 意义不大

使用不等于 查询

## select from table limit 100和limit 10000,100时间上一样吗？

前者时间短 后者需要查询偏移量前面的数据

# 事务

## 什么是数据库事务

**事务**：逻辑上的一组操作，要么都执行要么都不执行

**数据库事务**：一组SQL语句要么全部成功要么全部失败

> 事务由MySQL的引擎实现 InnoDB支持  MyISAM不支持事务
---
具体例子： 转账例子： 
三个操作为
	1.读A
	2.减A
	3.增B
这三个操作是不可分割的，要么全部执行成功 ，要么全部失败，不允许出现中间状态的数据。

事务保障：如果中途发生故障，要回滚到没执行该事务之前的状态。

## --如何开启事务

~~~mysql
# 开启一个事务
START TRANSACTION;
# 多条 SQL 语句
SQL1,SQL2...
## 提交事务
COMMIT;
~~~

## 事务特性（特征
> 事务由引擎支持，不是所有引擎都能支持事务；InnoDB支持

ACID

A**原子性Atomicity** 一个事务中的所有操作，要么都做or都不做；事务执行中发生错误，就会被回滚到事务开始前的状态，就好像这个事务没有发生过一样。

C**一致性Consistency** 事务结果把数据库从一个一致性状态变为另一个一致性状态（一致eg:转账无论是否成功，转账者和收款人的总额是不变的

**I隔离性Isolation**  数据库允许多个并发事务同时对其数据进行读写和修改的能力，即一个事务内部的操作及使用的数据对其它并发事务是隔离的，**并发执行的各个事务之间不能互相干扰。**隔离性要防止多个事务并发执行由于交叉执行而导致数据的不一致。

D**持久性Durability** 事务提交后，对数据库的改变是永久性的；故障不会对执行结果有任何影响

**C一致性是目的**



## 并发事务带来问题（这部分就是隔离性

> MySQL服务端允许多个客户端连接，会出现处理多个事务的情况，同时处理多个事务时，会出现  脏读、幻读、不可重复读的问题。
>
> 简答：
>
> - 脏读：读到其他事务未提交的数据；
> - 不可重复读：前后读取的数据不一致；
> - 幻读：前后读取的记录数量不一致。

### 脏读

概念：**一个事务「读到」了另一个「未提交事务修改过的数据」**

A读取到了另一个事务B修改但还没提交的数据 然后B回滚 A读取到脏数据

![图片](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292156027.png)

### 不可重复读

概念：**在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况**

即一个事务两次读一个数据的过程之间被另一个事务修改数据，多次读结果不一致

![图片](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292157916.png)

### 幻读

**在一个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了「幻读」现象**

两次读 第二次多了一些记录，中间被某个事务插入数据

> 不一样  多了或者少了都是不一样

![图片](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292157487.png)





### 解决幻读的方法

核心思想：一个事务操作某张表的时候，另一个事务不允许新增or删除表数据

1. 隔离级别调整 可序列化
2. 可重复读下 表添加表锁
3. 可重复读下  表添加`Next-key Lock（Record Lock+Gap Lock）`

### 用什么锁去解决的幻读问题

1. 可重复读下 表添加表锁
2. 可重复读下  表添加`Next-key Lock（Record Lock+Gap Lock）`

### 不用序列化怎么解决幻读

1. 可重复读下 表添加表锁
2. 可重复读下  表添加`Next-key Lock（Record Lock+Gap Lock）`

## 数据库的事务隔离级别及各自解决问题

> 四种隔离级别 规避脏读 不可重复读 幻读 三个问题

三个问题的严重问题排序

![图片](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292200848.png)

下列为四种隔离级别，隔离级别越高，性能效率越低（下图排序）

![图片](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292203737.png)

- **读未提交read uncommitted **一个事务还没提交时，它做的变动别的事务能看到
- **读提交 read committed** 允许读取并发事务已经提交的数据 ==解决脏读==
- **可重复读 repeatable read** 指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的；**MySQL InnoDB 引擎的默认隔离级别**； ==解决不可重复读==
- **可串行化（可序列化）serializable**  会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行；==解决幻读==

各个级别解决问题一览

![图片](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292204489.png)

注意

- mysql默认为RR可重复读
- 不建议使用串行化级别，性能效率低
- 不同数据库对隔离级别的支持不一样。其中**我们讨论的 MySQL 虽然支持 4 种隔离级别，但是与SQL 标准中规定的各级隔离级别允许发生的现象却有些出入**。
- mysql在可重复读的级别下，可以==很大程度==避免幻读现象发生，因此不会使用串行化级别，该级别影响性能

## mysql怎么实现事务

> 同样问题:
>
> - 事务实现原理
> - mysql怎么实现事务
> - InnoDB如何保证事务的四个特性？

简答：

- 持久性D是通过 redo log （重做日志）来保证的；
- 原子性A是通过 undo log（回滚日志） 来保证的；
- 隔离性I是通过 MVCC（多版本并发控制） 或 锁机制来保证的；
- 一致性C则是通过持久性+原子性+隔离性来保证；

mysql事务要满足acid特性，mysql事务原理就是innodb如何保证事务的acid特性；

原子性是 多个DML操作要么成功要么失败，失败就意味着数据回滚，innodb设计 undo log 日志，在事务执行过程中把修改前的数据块找保存到undo log里面，出错就回滚

一致性：数据的完整性约束没有被破坏，依赖业务层面，数据库中有主键的唯一约束 类型等保障

隔离性；多个并行事务对同一个数据操作 避免多个事务干扰 innodb提供四种隔离级别实现 默认是可重复读 采用**MVCC机制**解决脏读 不可重复读  采用行锁 表锁解决幻读

持久性：事务提交成功 对数据影响是永久的 因为用buffer pool，先更新内存缓冲区，可能出现数据丢失的问题，引入redo log 存储数据库变更后的值



事务进行数据库更改的时候，除了修改buffer pool 还会把修改redolog ,事务提交的时候 redolog 写入磁盘  宕机，重启mysql可以用redolog日志；



## Mysql解决幻读

> mysql四种隔离级别 与上面SQL规定的有些区别 
>
> mysql在可重复读 级别下，很大程度可以避免幻读，所以不会采用可序列化

Mysql 可重复读解决幻读 解决方案如下

- 针对**快照读**（普通 select 语句），是**通过 MVCC 方式解决了幻读**，因为可重复读隔离级别下，事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，即使中途有其他事务插入了一条数据，是查询不出来这条数据的，所以就很好了避免幻读问题。
- 针对**当前读**（select ... for update 等语句），是**通过 next-key lock（记录锁+间隙锁）方式解决了幻读**，因为当执行 select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范围内插入了一条记录，那么这个插入语句就会被阻塞，无法成功插入，所以就很好了避免幻读问题。

## 一般数据库默认隔离级别

可重复读RR，该级别解决 脏读 不可重复读 仍有可能幻读

## --mysql事务的隔离级别如何实现

基于锁和MVCC机制共同实现

1.读未提交：直接读取即可

2.读已提交READ-COMMITTED MVCC

3.可重复读:REPEATABLE-READ MVCC

4.串行化serializable  加读写锁实现；

---

「读提交」和「可重复读」通过 Read View 来实现，它们的区别在于创建 Read View 的时机不同，大家可以把 Read View 理解成一个数据快照，就像相机拍照那样，定格某一时刻的风景。

**「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View**

**「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。**

可重复读在**当前读**情况下也需要**加锁读**保证不出现幻读，即MVCC+锁

## --什么是当前读和快照读

**快照读 **读取某一个快照建立时(可以理解为某一时间点)的数据 （read-view就是通过快照读生成的

- 快照读主要体现在 select 时，不同隔离级别下，select 的行为不同在 
  - Serializable 隔离级别下 - 普通 select 也变成当前读（共享读锁
  - 在RC读可提交隔离级别下-每次 select 都会建立新的快照（还是类似当前读
  - 在RR可重复读取隔离级别下
    - 事务启动后，首次 select 会建立快照
    - 如果事务启动选择了 with consistent snapshot，事务启动时就建立快照
    - 基于旧数据的修改操作，会重新建立快照

我们前面讲过MVCC机制实现了快照读，**普通select 查询**就是快照读，快照读到数据有可能不是最新的数据，它主要是为了实现可重复读的事务隔离级别。
**当前读** ，即读取最新提交的数据

select...for update

insert，update，delete，都会按照最新提交的数据操作

当前读就是加了锁的增删改查语句。

> 锁
>
> 给读操作加上共享锁、排它锁，DML操作加上排它锁，这些操作就是当前读。
>
> 共享锁、排它锁也被称之为读锁、写锁。
>
> 共享锁与共享锁是共存的，但是要修改、添加、删除时，必须等到共享锁释放才可进行操作。
>
> 因为在Innodb存储引擎中，DML操作都会隐式添加排它锁。
>
> 所以说当前读所读取的记录就是最新的记录，读取数据时加上锁，保证其它事务不能修改当前记录。

**面试官问:关于MVCC 有没有解决幻的问题?**
在**快照读**的情况下，InnoDB通过MVCC机制解决了幻读现象;

**当前读**的情况下，innoDB是无法通过MVCC解决幻读的现象，因为它每次读取的都是最新的数据

## MVCC
> 参考
> [一文读懂数据库的MVCC实现原理 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/428066667)
> [看一遍就理解：MVCC原理详解 - 掘金 (juejin.cn)](https://juejin.cn/post/7016165148020703246)
> [(18条消息) MVCC 机制的原理及实现_不会写代码的coder的博客-CSDN博客](https://blog.csdn.net/qq_41361506/article/details/108538702)
> [(18条消息) 史上最详尽，一文讲透 MVCC 实现原理_DILIGENT203的博客-CSDN博客](https://blog.csdn.net/DILIGENT203/article/details/100751755)
> [面试官：什么是当前读和快照读？ - 掘金 (juejin.cn)](https://juejin.cn/post/7108567890323832869)
> [(18条消息) 【MySQL】面试题之：MVCC能否解决幻读？_mysql mvcc解决了幻读吗_cafe-BABE的博客-CSDN博客](https://blog.csdn.net/qq_35590091/article/details/107734005?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-107734005-blog-115532014.235^v38^pc_relevant_default_base&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2~default~CTRLIST~Rate-1-107734005-blog-115532014.235^v38^pc_relevant_default_base&utm_relevant_index=2)
> [(18条消息) 数据库面试题：mysql当前读和快照读（MVCC）_我是方小磊的博客-CSDN博客](https://blog.csdn.net/weixin_44844089/article/details/115532014#:~:text=快照读，顾名思义,保证读写不冲突。)
> [【MySQL】当前读、快照读、MVCC - wwcom123 - 博客园 (cnblogs.com)](https://www.cnblogs.com/wwcom123/p/10727194.html)
> [MySQL MVCC的实现 - read view解读 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/465940535)
> [(18条消息) MVCC实现原理之ReadView(一步到位)_read view_一个风轻云淡的博客-CSDN博客](https://blog.csdn.net/m0_62436868/article/details/127202062)
> [MySQL 的可重复读到底是怎么实现的？图解 ReadView 机制 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/166152616)
> [Mysql隔离级别之MVCC的ReadView的理解 - 简书 (jianshu.com)](https://www.jianshu.com/p/4c616f3a2844)
> [mysql 版本链机制 & readView - 简书 (jianshu.com)](https://www.jianshu.com/p/1f275c7267b2)
> [(18条消息) 【数据库】MySQL的ReadView_数据库view的数据是什么时候做成的_thesprit的博客-CSDN博客](https://blog.csdn.net/thesprit/article/details/112970122)

---

MVCC是多版本并发控制；
实现：MVCC实现是通过保存数据在某个时间点的快照实现的。

特点：根据事务开始的时间不同，每个事务对同一张表，同一时刻看到的数据可能是不一样的

MVCC主要实现 可重复读 读已提交 这两个隔离级别

mvcc使用快照读解决了部分幻读问题，但是在修改时还是使用当前读，所以还是存在幻读问题，幻读问题最终就是使用间隙锁next-lock key解决

**MVCC实现依赖于 1隐藏字段、2UNdo log、 3READ VIEW**

### 整体操作流程

1. 首先获取事务自己的版本号，也就是事务 ID；

2. 获取 ReadView；

3. 查询得到的数据，然后与 ReadView 中的事务版本号进行比较；

4. 如果不符合 ReadView 规则，就需要从 Undo Log 中获取历史快照；

5. 最后返回符合规则的数据。 在隔离级别为读已提交（Read Committed）时，一个事务中的每一次 SELECT 查询都会重新获取一次Read View。

### MVCC的实现原理

对于 InnoDB ，聚簇索引记录中包含 3 个隐藏的列

- DB_ROW_ID：隐藏的自增id，没主键就按照这个 聚簇索引
- 事务ID DB_TRX_ID：最后一次修改该记录的事务id
- 回滚指针DB_ROLL_PTR：指向这个记录上一个版本,该行对应的undo log的指针

![image-20230721161701754](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292221481.png)

历史版本存放在undo log中。如果要执行更新操作，会将原记录放入 undo log 中，并通过隐藏的回滚指针指向 undo log 中的原记录。

其它事务在这个事务修改时需要查询时，就是查询 undo log 中这行数据的最后一个历史版本。

MVCC 最大的好处是读不加锁，读写不冲突，极大地增加了 MySQL 的并发性。通过 MVCC，保证了事务 ACID 中的 I（隔离性）特性。

### 快照读如何避免幻读

可重复读级别 由MVCC实现，

**实现方式**

开始事务后(begin语句后)，执行第一个查询语句后，创建一个Read View，**后续的查询语句利用这个 Read View，通过这个 Read View 就可以在 undo log 版本链找到事务开始时的数据，所以事务过程中每次查询的数据都是一样的**，即使中途有其他事务插入了新纪录，是查询不出来这条数据的，所以就很好了避免幻读问题。

### 当前读如何避免幻读

MySQL 里除了普通查询是快照读，其他都是**当前读**，比如 update、insert、delete、select...for update，这些语句执行前都会查询最新版本的数据，然后再做进一步的操作。

这很好理解，假设你要 update 一个记录，另一个事务已经 delete 这条记录并且提交事务了，这样不是会产生冲突吗，所以 update 的时候肯定要知道最新的数据。

另外，`select ... for update` 这种查询语句是当前读，每次执行的时候都是读取最新的数据。

---

当前读带来问题(默认不加锁)：`select ... for update`，两次读之间插入 会幻读

**Innodb 引擎为了解决「可重复读」隔离级别使用「当前读」而造成的幻读问题，就引出了间隙锁**。

间隙锁例子：

![image-20230829221951400](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292219490.png)

查询条件加上id，会加上id范围(2,+∞)的间隙锁next-key lock （next-key lock 是间隙锁+记录锁的组合）。

事务 B 在执行插入语句的时候，判断到插入的位置被事务 A 加了 next-key lock，于是事物 B 会生成一个插入意向锁，同时进入等待状态，直到事务 A 提交了事务。这就避免了由于事务 B 插入新记录而导致事务 A 发生幻读的现象。

### 幻读被完全解决了吗

**可重复读隔离级别下虽然很大程度上避免了幻读，但是还是没有能完全解决幻读**。

> 两个发生幻读的例子
>
> 一
>
> 二
>
> 除了上面这一种场景会发生幻读现象之外，还有下面这个场景也会发生幻读现象。
>
> - T1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id > 100 得到了 3 条记录。
> - T2 时刻：事务 B 往插入一个 id= 200 的记录并提交；
> - T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id > 100 for update 就会得到 4 条记录，此时也发生了幻读现象。
>
> **要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select ... for update 这类当前读的语句**，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。

### --Read View在MVCC里面如何工作



### --可重复读是如何工作的



### -- 读提交是如何工作的

## mysql为什么能实现可重复读

MVCC

## 事务和日志的原理。

即事务实现原理和MVCC

# 分库分表

mysql一张表数据量过大就要分库分表

## 数据库分库分表了解吗，只分库不分表可以吗，只分表不分库可以吗（



## 了解数据库单表能支撑的数据量吗

2000w

2000 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。

# 锁

锁按照粒度分为表锁、行锁、页锁。

按照使用方式分为共享锁、排它锁。

根据思想分为乐观锁、悲观锁。

无论是乐观锁、悲观锁都只是一种思想而已，并不是实际的锁机制，这点一定要清楚。

## 乐观锁悲观锁讲讲

悲观锁：消极态度，认为每次访问数据总是产生冲突，每次访问先锁住数据

适合**写多读少**

乐观锁:认为即使在并发环境下，外界对数据的操作不会产生冲突，所以不会去加锁，而是会在提交更新的时候才会正式的对数据冲突与否进行检测。





Innodb的MVCC机制就是乐观锁的一种体现，读不加锁，读写不冲突，在不加锁的情况下能让多个事务进行并发读写，并且解决读写冲突问题，极大的提高系统的并发性

## mysql乐观锁实现， 介绍其他S,X悲观锁，说明加锁原理



## 表级锁和行级锁 有什么区别

表级锁一锁就锁整张表

行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁）

区别：

1.锁定粒度不一样  表/行记录

2. 针对非索引字段/索引字段
3. 不会出现死锁 /会死锁
4. 高并发效率低/高
5. 加锁开销小/大



MyISAM采用表级锁

InnoDB支持**行级和表级锁**

## mysql行锁

Innodb支持三种

- 记录锁record lock;属于单个行记录上的锁
- 间隙锁gap lock:锁定一个范围，不包括记录本身。
- 临键锁next-key lock:Record Lock+Gap Lock，锁定一个范围，包含记录本身，主要目的是为了解决幻读问题（MySQL 事务部分提到过）。记录锁只能锁住已经存在的记录，为了避免插入新记录，需要依赖间隙锁。

## --什么sql会加行级锁

在事务中

```sql
//对读取的记录加共享锁(S型锁)
select ... lock in share mode;

//对读取的记录加独占锁(X型锁)
select ... for update;
```

```sql
//对操作的记录加独占锁(X型锁)
update table .... where id = 1;

//对操作的记录加独占锁(X型锁)
delete from table where id = 1;
```

## --共享锁和排他锁

共享锁 s锁 share lock

独占锁 x锁 exclusive lock

|      | S 锁   | X 锁 |
| :--- | :----- | :--- |
| S 锁 | 不冲突 | 冲突 |
| X 锁 | 冲突   | 冲突 |



## MySQL中innodb引擎中行级锁的类型

记录·

间隙

临键锁

## --innodb如何实现行锁

基于索引  

`例: select * from tab_with_index where id = 1 for update;`
for update 可以根据条件来完成行锁锁定，并且 id 是有索引键的列，如果 id 不是索引键那么InnoDB将完成表锁，并发将无从谈起

## MySQL中锁和事务是否有相关性？

事务隔离级别 与锁有关

读可提交：读取加共享锁 语句执行完释放共享锁

可重复读：读取加共享锁  事务提交之前不释放，等待事务执行完毕释放

可序列化：锁定表范围

# 一致性

先更新数据库再删缓存  先删除缓存再更新数据库（这要用到延时双删来保证一致性） 延时双删怎样实现的 加锁 只准一个线程操作

## 如何保持数据库和缓存数据一致性？为什么要用二级缓存？

## 间隙锁

# 日志

> 参考
>
> 1.小林coding

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292142690.png)

## --常见的日志有哪些

> binlog 和redo log/undo log比较重要

- 二进制日志binlog： 更改数据库数据的 SQL 语句
- 事务日志redolog undolog：redo log 是重做日志，undo log 是回滚日志。
  - redo log；实现事务的**持久性**，主要用于掉电等故障恢复
  - undo log：实现事务的**原子性**，用于事务回滚和MVCC
- 错误日志error log： 对 MySQL 的启动、运行、关闭过程进行了记录。
- 慢查询日志 **slow query log**：记录执行时间超过long_query_time的查询，解决sql慢查询问题 默认不开启
- 一般查询日志 general query log：已经建立连接的客户端发送给服务器的所有mysql记录 默认不开启



## bin log

记录了 MySQL **数据库中数据的所有变化**(数据库执行的所有 DDL 和 DML 语句)。记录语句，就逻辑日志



主要应用场景：主从复制和备份恢复

## redo log

保证事务的**持久性C**

一般mysql对内存中的buffer pool进行操作，如果pool里面修改还未持久化，就宕机；就违反持久性

重启时根据redo log重做写入磁盘

事务执行的过程中就写入redo

redo log 保证事务持久性。redo log记录页的修改；每个事务提交时会把redo log写到磁盘上，即使崩溃 也能恢复未写入磁盘的数据

注意设置 刷盘策略  设置为一才能保证不会丢失任何数据

## 页修改后为何不直接刷盘

一页16KB，一行redo log 几十个字节 效率不一样

## undo log

作用：保证事务**原子性A**

每一个事务对数据的修改都会被记录到 undo log ，当执行事务过程中出现错误或者需要执行回滚操作的话，MySQL 可以利用 undo log 将数据恢复到事务开始之前的状态。

undo log记录的是**SQL语句**

### 作用（为什么需要undo log

1.事务回滚，保证原子性

2.**实现MVCC多版本控制**的关键因素；MVCC通过ReadView+undo log实现

## redo log  bin log区别

- bin log数据库还原 数据级别数据恢复 也用主从复制   redo log 事务持久性，属于事务级别的数据恢复
- redolog  innodb引擎持有  binlog 所有引擎持有，mysql server层实现
- redolog 是物理日志 记录某一页修改 binlog是逻辑日志 记录语句
- redolog 循环写 到结尾会回到开头，binlog 无大小限制

# 内存（buffer pool详解

> 这一块 没什么面试题 看的小林coding

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292142713.png)

## 为什么要有Buffer Pool

Mysql为了提升性能，把查询到的数据缓存内存中，方便下次查询；

Innodb引擎设计了缓存池**Buffer Pool**

如图：

<img src="https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308071424090.png" alt="img" style="zoom:50%;" />

有了缓存池后读写过程：

- 当**读取**数据时，如果数据存在于 Buffer Pool 中，客户端就会直接读取 Buffer Pool 中的数据，否则再去磁盘中读取。
- 当**修改**数据时，首先是修改 Buffer Pool 中数据所在的页，然后将其页设置为**脏页**，最后由**后台线程将脏页写入到磁盘**

### Buffer Pool有多大

默认128MB；可以通过调整 `innodb_buffer_pool_size` 参数来设置 Buffer Pool 的大小

### Buffer Pool缓存什么

**数据划分**

InnoDB 会把存储的数据划分为若干个「页」，以页作为磁盘和内存交互的基本单位，一个页的默认大小为 16KB。**因此，Buffer Pool 同样需要按「页」来划分。**

在 MySQL 启动的时候，**InnoDB 会为 Buffer Pool 申请一片连续的内存空间，然后按照默认的`16KB`的大小划分出一个个的页， Buffer Pool 中的页就叫做缓存页**。此时这些缓存页都是空闲的，之后随着程序的运行，才会有磁盘上的页被缓存到 Buffer Pool 中。

---

**里面的数据**

索引页，数据页，undo页，插入缓存、自适应哈希索引、锁信息

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292142269.png)

**buffer pool中的控制块**

管理缓存页：每个缓存页建了一个**控制块**；

控制块信息:「缓存页的表空间、页号、缓存页地址、链表节点」

控制块位置:控制块也是占有内存空间的，它是放在 Buffer Pool 的最前面，接着才是缓存页

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292142368.png)

上图中控制块和缓存页之间灰色部分称为碎片空间。

> 为什么会有碎片空间
>
> 每一个控制块都对应一个缓存页，剩余空间可能不够分配一对控制块和缓存页



> 查询一条记录，就只需要缓冲一条记录吗？
>
> no：当我们查询一条记录时，InnoDB 是会把整个页的数据加载到 Buffer Pool 中，因为，通过索引只能定位到磁盘中的页，而不能定位到页中的一条记录。将页加载到 Buffer Pool 后，再通过页里的页目录去定位到某条具体的记录。



## 如何管理Buffer Pool

缓存页分类:

- Free Page（空闲页），表示此页未被使用
- Clean Page（干净页），表示此页已被使用，但是页面未发生修改
- Dirty Page（脏页），表示此页「已被使用」且「已经被修改」，其数据和磁盘上的数据已经不一致。



### 如何管理空闲页

bufferpool是一片连续的内存空间，需要快速找到空闲缓存页；

使用链表结构快速查找:将空闲缓存页的「控制块」作为链表的节点，这个链表称为 **Free 链表**（空闲链表）。

[外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-LfxGCK06-1693153583495)(https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308071439055.png)]

Free链表结构

- Free链表头节点：记录链表头尾节点地址，以及当前链表节点数量
- 链表结点：一个个控制块，记录对应缓存页地址

**有了free链表如何查找空闲页**

每当需要从磁盘中加载一个页到 Buffer Pool 中时，就从 Free链表中取一个空闲的缓存页，并且把该缓存页对应的控制块的信息填上，然后把该缓存页对应的控制块从 Free 链表中移除。

### 如何管理脏页

bufferpool 也要提高写性能，更新时间的时候不能每次写入磁盘。于是写的时候标记对应缓存页为脏页，由后台线程将脏页写入磁盘。

**Flush链表**：控制脏页

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292142796.png)

有了 Flush 链表后，后台线程就可以遍历 Flush 链表，将脏页写入到磁盘。

### 如何提高缓存命中率

缓存大小有限，希望淘汰不需要的数据。

从LRU算法引出两个问题再改进



LRU算法**(未被Mysql使用)**

概述:

简单的 LRU 算法的实现思路

- 当访问的页在 Buffer Pool 里，就直接把该页对应的 LRU 链表节点移动到链表的头部。
- 当访问的页不在 Buffer Pool 里，除了要把页放入到 LRU 链表的头部，还要淘汰 LRU 链表末尾的节点

综上，bufferpool有三种链表和页管理数据

![img](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292142681.png)

- Free Page（空闲页），表示此页未被使用，位于 Free 链表；
- Clean Page（干净页），表示此页已被使用，但是页面未发生修改，位于LRU 链表。
- Dirty Page（脏页），表示此页「已被使用」且「已经被修改」，其数据和磁盘上的数据已经不一致。当脏页上的数据写入磁盘后，内存数据和磁盘数据一致，那么该页就变成了干净页。脏页同时存在于 LRU 链表和 Flush 链表。



存在问题

- 预读失败
- buffer pool污染

> 什么是预读失败？
>
> myqsl加载数据页利用空间局部性加载相邻的数据页，减少磁盘IO。
>
> 预读失败指**被提前加载进来的数据页，并没有被访问**
>
> 简单LRU把预读页放入头部，而当 Buffer Pool空间不够的时候，还需要把末尾的页淘汰掉。
>
> 如果这些预读页如果一直不会被访问到，就会出现一个很奇怪的问题，不会被访问的预读页却占用了 LRU 链表前排的位置，而末尾淘汰的页，可能是频繁访问的页，这样就大大降低了缓存命中率。

> 怎么解决预读失效而导致缓存命中率降低的问题？
>
> **让预读的页停留在 Buffer Pool 里的时间要尽可能的短，让真正被访问的页才移动到 LRU 链表的头部，从而保证真正被读取的热数据留在 Buffer Pool 里的时间尽可能长**。

**Mysql对预读失败问题改进的LRU算法**

LRU分为两个区域   old /young区域  young区域在前半部分，old在后半部分

![image-20230807145938366](https://duoduo-img.oss-cn-shenzhen.aliyuncs.com/202308292142857.png)

**划分这两个区域后，预读的页就只需要加入到 old 区域的头部，当页被真正访问的时候，才将页插入 young 区域的头部**。如果预读的页一直没有被访问，就会从 old 区域移除，这样就不会影响 young 区域中的热点数据。

注意，仍未解决bufferpool污染问题

> 什么是bufferpool污染
>
> 当某一个 SQL 语句**扫描了大量的数据**时，在 Buffer Pool 空间比较有限的情况下，可能会将 **Buffer Pool 里的所有页都替换出去，导致大量热数据被淘汰了**，等这些热数据又被再次访问的时候，由于缓存未命中，就会产生大量的磁盘 IO，MySQL 性能就会急剧下降，这个过程被称为 **Buffer Pool 污染**。
>
> eg:模糊查询 导致索引失效 全表扫描
>
> - 从磁盘读到的页加入到 LRU 链表的 old 区域头部；
> - 当从页里读取行记录时，也就是页被访问的时候，就要将该页放到 young 区域头部；
> - 接下来拿行记录的 name 字段和字符串 xiaolin 进行模糊匹配，如果符合条件，就加入到结果集里；
> - 如此往复，直到扫描完表中的所有记录。

> 如何解决污染
>
> 提高进入young区域的门槛

mysql解决bufferpool污染

进入到 young 区域条件增加了一个**停留在 old 区域的时间判断**

- 如果后续的访问时间与第一次访问的时间**在某个时间间隔内**，那么**该缓存页就不会被从 old 区域移动到 young 区域的头部**；
- 如果后续的访问时间与第一次访问的时间**不在某个时间间隔内**，那么**该缓存页移动到 young 区域的头部**；

这个间隔时间是由 `innodb_old_blocks_time` 控制的，默认是 1000 ms。

也就说，**只有同时满足「被访问」与「在 old 区域停留时间超过 1 秒」两个条件，才会被插入到 young 区域头部**，这样就解决了 Buffer Pool 污染的问题 。

### 脏页什么时候会被刷入磁盘

防止宕机丢失数据，脏页未写入:

InnoDB 的更新操作采用的是 Write Ahead Log 策略，即先写日志，再写入磁盘，通过 redo log 日志让 MySQL 拥有了崩溃恢复能力。

触发脏页刷新的情况：



# 主从同步

如何实现主从数据库同步的

## 主从原理





快手

1. MySQL索引有哪些数据结构
2. innodb的索引结构
3. 为什么用B+树
4. 非聚簇索引和聚簇索引的区别
5. 索引失效的情况
6. select from table limit 100和limit 10000,100时间上一样吗？
7. 数据库优化策略

---

1.底层数据结构，
2.主键索引与非主键索引
3.根据范围查找时B+树对比B树
4.隔离级别以及各自解决问题
5.有一条sql语句执行很慢，怎么排查问题

---

介绍Mysql脏读、不可重复读、幻读。
22、默认隔离级别。
23、用过索引吗？用过 辅助索引、 联合索引。~~
24、添加索引的原则。(where、range。。。)
复盘到这里 感觉自己好菜。。。
25、索引的分类
26、主键索引和非主键索引。(Innodb 下 ，叶子节点存放的区别 ，是否会产生回表 这两个角度说了)
27、用过sql执行计划吗？explain。做一些慢查询优化的东西。(从重点关注的四个字段段说了起来)

---

5.mysql事务 隔离级别

6.索引结构

7.索引什么时候会失效

8.查询优化

9.mysql行锁

10. redolog redolog binlog mvcc

11.主从原理



---

6、mysql索引概念？索引数据结构？事务的隔离级别？一般数据库默认的隔离级别？

---

6、mysql索引结构 为什么要用b+树 什么情况下不走索引

7、缓存数据库不一致怎么解决

---

mysql隔离级别

---

索引的数据结构

6、B树和B+树什么意思，区别在哪

7、聚簇索引和非聚簇索引

8、事务、ACID、MySQL默认隔离级别，什么是幻读，不用序列化怎么解决幻读

9、间隙锁



# SQL优化（有哪些常见的sql优化手段

> 参考
>
> 1.javaguide sql优化 付费版面试指南

面试题：有哪些常见的SQL优化手段

**简答:**

1. 避免使用 SELECT *
2. 分页优化
3. 尽量避免多表做 join
4. 建议不要使用外键与级联
5. 选择合适的字段类型
6. 尽量用 UNION ALL 代替 UNION
7. 批量操作Show Profile 分析 SQL 执行性能
8. 优化慢 SQL
9. 正确使用索引

### 避免使用SELECT *

`SELECT *`

1.消耗更多CPU

2.多余的无用字段增加网络带宽消耗，增加数据传输时间

3.无法使用mysql优化器 `覆盖索引`的 优化策略

4.使用具体字段`select<字段列表>`，可以减少表结构变更带来的影响

### 分页优化

数据量百万级时，普通的分页耗费时间长

子查询or延迟查询 具体略



参考：

[面试官：一千万数据，怎么快速查询？ - 掘金 (juejin.cn)](https://juejin.cn/post/6863668253898735629)

[【得物技术】MySQL深分页优化 - 掘金 (juejin.cn)](https://juejin.cn/post/6985478936683610149)

### 避免多表做join

三张及以上禁止join

实际业务场景避免多表 join 常见的做法有两种:

- **单表查询后在内存中自己做关联:**对数据库做单表查询，再根据查询结果进行二次查询，以此类推最后再进行关联。
- **数据冗余**，把一些重要的数据在表中做几余，尽可能地避免关联查询。很笨的一种做法，表结构比较稳定的情况下才会考虑这种做法。进行几余设计之前，思考一下自己的表结构设计的是否有问题。

更加推荐第一种，这种在实际项目中的使用率比较高，除了性能不错之外，还有如下优势:

### 避免外键和级联

级联更新强阻塞，存在更新风暴的风险。

级联指级联更新、级联删除

### 选择合适的字段类型

存储字节越小，占用空间越小，性能越好。

**a.某些字符串可以转换成数字类型存储比如可以将 IP 地址转换成整型数据**
数字是连续的，性能更好，占用空间也更小。
MySQL 提供了两个方法来处理 ip 地址

- INET ATON() : 把 ip 转为无符号整型(4-8 位)
- INET NTOA() :把整型的 ip 转为地址

插入数据前，先用 INET ATON() 把 p 地址转为整型，显示数据时，使用 INET NTOA() 把整型的 ip 地址转为地址显示即可。
**b.对于非负型的数据(如自增 D,整型 IP，年) 来说,要优先使用无符号整型来存储**
无符号相对于有符号可以多出一倍的存储空间

**c.小数值类型 (比如年龄、状态表示如 0/1) 优先使用 TINYINT 类型**

**d.对于日期类型来说，DateTime 类型耗费空间更大且没有时区信息，建议使用 Timestamp。**

**e.金额字段用 decimal，避免精度丢失**

**f.尽量使用自增 id 作为主键**

如果主键为自增 id 的话，每次都会将数据加在 B+树尾部(本质是双向链表)，时间复杂度为 O(1)。在写满一个数据页的时候，直接申请另一个新数据页接着写就可以了。
如果主键是非自增 id 的话，为了让新加入数据后 B+树的叶子节点还能保持有序，它就需要往叶子结点的中间找，查找过程的时间复杂度是 O(lgn)。如果这个也被写满的话，就需要进行页分裂。页分裂操作需要加悲观锁，性能非常低。

不过，像分库分表这类场景就不建议使用自增 id 作为主键，应该使用分布式ID 比如 uuid。

[数据库主键一定要自增吗?哪些场景不建议自增](https://mp.weixin.qq.com/s/vNRIFKjbe7itRTxmq-bkAA)

### 尽量用UNION ALL代替UNION

UNION 会把两个结果集的所有数据放到临时表中后再进行去重操作，更耗时，更消耗 CPU 资源.
UNION ALL 不会再对结果集进行去重操作，获取到的数据包含重复的项

不过，如果实际业务场景中不允许产生重复数据的话，还是可以使用 UNION

### 批量操作

对于数据库中的数据更新，如果能使用批量操作就要尽量使用，减少请求数据库的次数，提高性能.

~~~mysql
#反例
INSERT INTO `cus_order` (`id`,`score`,`name`)
VALUES (1，426547,'user1');
INSERT INTO `cus_order` (`id`,`score`,`name`)
VALUES (2，33,'user2');
INSERT INTO `cus_order` (`id`,`score`,`name`)
VALUES (1，293854,'user3');
#正例
INSERT into `cus_order` (`id`,`score`,`name`) 
values(1，426547，'user1'),(1，33，'user2'),(1, 293854, 'user3');
~~~

### Show Profile 分析SQL执行性能

为了更精准定位一条 SQL 语句的性能问题，需要清楚地知道这条 SQL 语句运行时消耗了多少系统资源

`SHOW PROFILE` 和 `SHOW PROFILES` 展示 SQL 语句的资源使用情况，展示的消息包括 CPU 的使用，CPU 上下文切换，IO 等待，内存使用等。
MySQL在 5.0.37 版本之后才支持 Profiling， select @@have_profiling 命令返回 YES 表示该功能可以使用。

~~~mysql
@@have_profiling  
------------------
YES               
~~~



### 优化慢SQL

首先要找到哪些SQL语句执行速度慢。

从MYSQL慢查询日志找响应时间超过设定值的SQL语句。

该功能默认关闭

~~~mysql
# 开启慢查询日志功能
SET GLOBAL slow_query_log ='ON';
# 慢查询日志存放位置
SET GLOBAL slow_query_log_file ='/var/lib/mysql/ranking-list-slow.log';
#无论是否超时，未被索引的记录也会记录下来。
SET GLOBAL log queries not using indexes = 'ON';
# 慢查询阈值 (秒)，SOL 执行超过这个阈值将被记录在日志中。
SET SESSION long_query_time = 1;
# 慢查询仅记录扫描行数大于此参数的 SOL
SET SESSION min_examined_row_limit = 100;
~~~

设置成功之后，使用 `show variables like 'slow%'`;命令进行查看设置

执行慢sql后打开日志查询

找到慢sql后，通过`EXPLAIN`命令分析对应的`SELECT`语句(使用：在select语句前加EXPLAI即可)

type字段比较关键

all<index<range~index_merege

具体看[MySQL 性能优化神器 Explain 使用分析 - 后台开发 - SegmentFault 思否](https://segmentfault.com/a/1190000008131735)

### 正确使用索引

> 正确选择所有可以加快数据的检索速度

#### 选择合适的字段创建索引

**不为 NULL 的字段:**索引字段的数据应该尽量不为 NULL，因为对于数据为 NULL 的字段，数据库较难优化。如果字段频繁被查询，但又避免不了为 NULL，建议使用 0,1,true,false 这样语义较为清晰的短值或短字符作为替代。
**被频繁查询的字段:**我们创建索引的字段应该是查询操作非常频繁的字段。**被作为条件查询的字段:** 被作为 WHERE 条件查询的字段，应该被考虑建立索引。

**频繁需要排序的字段:** 索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。

**被经常频繁用于连接的字段:** 经常用于连接的字段可能是一些外键列，对于外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率。

#### 被频繁更新的字段应该慎重建立索引

虽然索引能带来查询上的效率，但是维护索引的成本也是不小的。 如果一个字段不被经常查询，反而被经常修改，那么就更不应该在这种字段上建立索引了。

#### 尽可能的考虑建立联合索引而不是单列索引

因为索引是需要占用磁盘空间的，可以简单理解为每个索引都对应着一颗 B+树。如果一个表的字段过多，索引过多，那么当这个表的数据达到一个体量后，索引占用的空间也是很多的，且修改索引时，耗费的时间也是较多的。如果是联合索引，多个字段在一个索引上，那么将会节约很大磁盘空间，且修改数据的操作效率也会提升。

#### 注意避免冗余索引

冗余索引指的是索引的功能相同，能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引。如(name,city )和(name ) 这两个索引就是冗余索引，能够命中前者的查询肯定是能够命中后者的。在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。

#### 考虑在字符串类型的字段上使用前缀索引代替普通索引

前缀索引仅限于字符串类型，较普通索引会占用更小的空间，所以可以考虑使用前缀索引代替普通索引

#### 避免索引失效

> 索引失效是慢查询的主要原因

索引失效的情况：

- 使用` SELECT *`进行查询
- 创建了组合索引，但查询条件未准守最左匹配原则;
- 在索引列上进行计算、函数、类型转换等操作;
- 以%开头的 LIKE 查询比如 `like %abc';`
- 查询条件中使用 or，且or 的前后条件中有一个列没有索引，涉及的索引都不会被使用到;
- 发生隐式转换

#### 删除长期未使用的索引

不用的索引的存在会造成不必要的性能损耗
